/**
 * @license
 * Copyright 2021 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
import { DocumentData as DocumentData_2 } from '@firebase/firestore-types';
import { FirebaseApp } from '@firebase/app-exp';
import { FirebaseAuthInternalName } from '@firebase/auth-interop-types';
import { _FirebaseService } from '@firebase/app-exp';
import { LogLevelString as LogLevel } from '@firebase/logger';
import { Provider } from '@firebase/component';
import { SetOptions as SetOptions_2 } from '@firebase/firestore-types';

/**
 * Converts Firestore's internal types to the JavaScript types that we expose
 * to the user.
 */
declare abstract class AbstractUserDataWriter {
  convertValue(
    value: Value,
    serverTimestampBehavior?: ServerTimestampBehavior
  ): unknown;
  private convertObject;
  private convertGeoPoint;
  private convertArray;
  private convertServerTimestamp;
  private convertTimestamp;
  protected convertDocumentKey(
    name: string,
    expectedDatabaseId: DatabaseId
  ): DocumentKey;
  protected abstract convertReference(name: string): unknown;
  protected abstract convertBytes(bytes: ByteString): unknown;
}

/**
 * Describes a map whose keys are active target ids. We do not care about the type of the
 * values.
 */
declare type ActiveTargets = SortedMap<TargetId, unknown>;

/**
 * Add a new document to specified `CollectionReference` with the given data,
 * assigning it a document ID automatically.
 *
 * @param reference - A reference to the collection to add this document to.
 * @param data - An Object containing the data for the new document.
 * @returns A Promise resolved with a `DocumentReference` pointing to the
 * newly created document after it has been written to the backend (Note that it
 * won't resolve while you're offline).
 */
export declare function addDoc<T>(
  reference: CollectionReference<T>,
  data: T
): Promise<DocumentReference<T>>;

declare interface ApiClientObjectMap<T> {
  [k: string]: T;
}

/**
 * Returns a special value that can be used with {@link (setDoc:1)} or {@link
 * updateDoc} that tells the server to remove the given elements from any
 * array value that already exists on the server. All instances of each element
 * specified will be removed from the array. If the field being modified is not
 * already an array it will be overwritten with an empty array.
 *
 * @param elements - The elements to remove from the array.
 * @returns The `FieldValue` sentinel for use in a call to `setDoc()` or
 * `updateDoc()`
 */
export declare function arrayRemove(...elements: unknown[]): FieldValue;

/**
 * Returns a special value that can be used with {@link setDoc} or {@link
 * updateDoc} that tells the server to union the given elements with any array
 * value that already exists on the server. Each specified element that doesn't
 * already exist in the array will be added to the end. If the field being
 * modified is not already an array it will be overwritten with an array
 * containing exactly the specified elements.
 *
 * @param elements - The elements to union into the array.
 * @returns The `FieldValue` sentinel for use in a call to `setDoc()` or
 * `updateDoc()`.
 */
export declare function arrayUnion(...elements: unknown[]): FieldValue;

declare interface AsyncQueue {
  readonly isShuttingDown: boolean;
  /**
   * Adds a new operation to the queue without waiting for it to complete (i.e.
   * we ignore the Promise result).
   */
  enqueueAndForget<T extends unknown>(op: () => Promise<T>): void;
  /**
   * Regardless if the queue has initialized shutdown, adds a new operation to the
   * queue without waiting for it to complete (i.e. we ignore the Promise result).
   */
  enqueueAndForgetEvenWhileRestricted<T extends unknown>(
    op: () => Promise<T>
  ): void;
  /**
   * Initialize the shutdown of this queue. Once this method is called, the
   * only possible way to request running an operation is through
   * `enqueueEvenWhileRestricted()`.
   */
  enterRestrictedMode(): void;
  /**
   * Adds a new operation to the queue. Returns a promise that will be resolved
   * when the promise returned by the new operation is (with its value).
   */
  enqueue<T extends unknown>(op: () => Promise<T>): Promise<T>;
  /**
   * Enqueue a retryable operation.
   *
   * A retryable operation is rescheduled with backoff if it fails with a
   * IndexedDbTransactionError (the error type used by SimpleDb). All
   * retryable operations are executed in order and only run if all prior
   * operations were retried successfully.
   */
  enqueueRetryable(op: () => Promise<void>): void;
  /**
   * Schedules an operation to be queued on the AsyncQueue once the specified
   * `delayMs` has elapsed. The returned DelayedOperation can be used to cancel
   * or fast-forward the operation prior to its running.
   */
  enqueueAfterDelay<T extends unknown>(
    timerId: TimerId,
    delayMs: number,
    op: () => Promise<T>
  ): DelayedOperation<T>;
  /**
   * Verifies there's an operation currently in-progress on the AsyncQueue.
   * Unfortunately we can't verify that the running code is in the promise chain
   * of that operation, so this isn't a foolproof check, but it should be enough
   * to catch some bugs.
   */
  verifyOperationInProgress(): void;
}

/**
 * Path represents an ordered sequence of string segments.
 */
declare abstract class BasePath<B extends BasePath<B>> {
  private segments;
  private offset;
  private len;
  constructor(segments: string[], offset?: number, length?: number);
  /**
   * Abstract constructor method to construct an instance of B with the given
   * parameters.
   */
  protected abstract construct(
    segments: string[],
    offset?: number,
    length?: number
  ): B;
  /**
   * Returns a String representation.
   *
   * Implementing classes are required to provide deterministic implementations as
   * the String representation is used to obtain canonical Query IDs.
   */
  abstract toString(): string;
  get length(): number;
  isEqual(other: B): boolean;
  child(nameOrPath: string | B): B;
  /** The index of one past the last segment of the path. */
  private limit;
  popFirst(size?: number): B;
  popLast(): B;
  firstSegment(): string;
  lastSegment(): string;
  get(index: number): string;
  isEmpty(): boolean;
  isPrefixOf(other: this): boolean;
  isImmediateParentOf(potentialChild: this): boolean;
  forEach(fn: (segment: string) => void): void;
  toArray(): string[];
  static comparator<T extends BasePath<T>>(
    p1: BasePath<T>,
    p2: BasePath<T>
  ): number;
}

/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
/**
 * BatchID is a locally assigned ID for a batch of mutations that have been
 * applied.
 */
declare type BatchId = number;

/**
 * Represents a bound of a query.
 *
 * The bound is specified with the given components representing a position and
 * whether it's just before or just after the position (relative to whatever the
 * query order is).
 *
 * The position represents a logical index position for a query. It's a prefix
 * of values for the (potentially implicit) order by clauses of a query.
 *
 * Bound provides a function to determine whether a document comes before or
 * after a bound. This is influenced by whether the position is just before or
 * just after the provided values.
 */
declare class Bound {
  readonly position: Value[];
  readonly before: boolean;
  constructor(position: Value[], before: boolean);
}

/**
 * Provides interfaces to save and read Firestore bundles.
 */
declare interface BundleCache {
  /**
   * Gets the saved `BundleMetadata` for a given `bundleId`, returns undefined
   * if no bundle metadata is found under the given id.
   */
  getBundleMetadata(
    transaction: PersistenceTransaction,
    bundleId: string
  ): PersistencePromise<BundleMetadata | undefined>;
  /**
   * Saves a `BundleMetadata` from a bundle into local storage, using its id as
   * the persistent key.
   */
  saveBundleMetadata(
    transaction: PersistenceTransaction,
    metadata: BundleMetadata_2
  ): PersistencePromise<void>;
  /**
   * Gets a saved `NamedQuery` for the given query name. Returns undefined if
   * no queries are found under the given name.
   */
  getNamedQuery(
    transaction: PersistenceTransaction,
    queryName: string
  ): PersistencePromise<NamedQuery | undefined>;
  /**
   * Saves a `NamedQuery` from a bundle, using its name as the persistent key.
   */
  saveNamedQuery(
    transaction: PersistenceTransaction,
    query: NamedQuery_2
  ): PersistencePromise<void>;
}

/** Properties of a BundledQuery. */
declare interface BundledQuery {
  /** BundledQuery parent */
  parent?: string | null;
  /** BundledQuery structuredQuery */
  structuredQuery?: StructuredQuery | null;
  /** BundledQuery limitType */
  limitType?: LimitType_2 | null;
}

/**
 * Represents a Firestore bundle saved by the SDK in its local storage.
 */
declare interface BundleMetadata {
  /**
   * Id of the bundle. It is used together with `createTime` to determine if a
   * bundle has been loaded by the SDK.
   */
  readonly id: string;
  /** Schema version of the bundle. */
  readonly version: number;
  /**
   * Set to the snapshot version of the bundle if created by the Server SDKs.
   * Otherwise set to SnapshotVersion.MIN.
   */
  readonly createTime: SnapshotVersion;
}

/** Properties of a BundleMetadata. */
declare interface BundleMetadata_2 {
  /** BundleMetadata id */
  id?: string | null;
  /** BundleMetadata createTime */
  createTime?: Timestamp_2 | null;
  /** BundleMetadata version */
  version?: number | null;
  /** BundleMetadata totalDocuments */
  totalDocuments?: number | null;
  /** BundleMetadata totalBytes */
  totalBytes?: number | null;
}

/**
 * An immutable object representing an array of bytes.
 */
export declare class Bytes {
  _byteString: ByteString;
  /** @hideconstructor */
  constructor(byteString: ByteString);
  /**
   * Creates a new `Bytes` object from the given Base64 string, converting it to
   * bytes.
   *
   * @param base64 - The Base64 string used to create the `Bytes` object.
   */
  static fromBase64String(base64: string): Bytes;
  /**
   * Creates a new `Bytes` object from the given Uint8Array.
   *
   * @param array - The Uint8Array used to create the `Bytes` object.
   */
  static fromUint8Array(array: Uint8Array): Bytes;
  /**
   * Returns the underlying bytes as a Base64-encoded string.
   *
   * @returns The Base64-encoded string created from the `Bytes` object.
   */
  toBase64(): string;
  /**
   * Returns the underlying bytes in a new `Uint8Array`.
   *
   * @returns The Uint8Array created from the `Bytes` object.
   */
  toUint8Array(): Uint8Array;
  /**
   * Returns a string representation of the `Bytes` object.
   *
   * @returns A string representation of the `Bytes` object.
   */
  toString(): string;
  /**
   * Returns true if this `Bytes` object is equal to the provided one.
   *
   * @param other - The `Bytes` object to compare against.
   * @returns true if this `Bytes` object is equal to the provided one.
   */
  isEqual(other: Bytes): boolean;
}

/**
 * @license
 * Copyright 2020 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
/**
 * Immutable class that represents a "proto" byte string.
 *
 * Proto byte strings can either be Base64-encoded strings or Uint8Arrays when
 * sent on the wire. This class abstracts away this differentiation by holding
 * the proto byte string in a common class that must be converted into a string
 * before being sent as a proto.
 */
declare class ByteString {
  private readonly binaryString;
  static readonly EMPTY_BYTE_STRING: ByteString;
  private constructor();
  static fromBase64String(base64: string): ByteString;
  static fromUint8Array(array: Uint8Array): ByteString;
  toBase64(): string;
  toUint8Array(): Uint8Array;
  approximateByteSize(): number;
  compareTo(other: ByteString): number;
  isEqual(other: ByteString): boolean;
}

/**
 * Constant used to indicate the LRU garbage collection should be disabled.
 * Set this value as the `cacheSizeBytes` on the settings passed to the
 * `Firestore` instance.
 */
export declare const CACHE_SIZE_UNLIMITED = -1;

declare const enum ChangeType {
  Added = 0,
  Removed = 1,
  Modified = 2,
  Metadata = 3
}

/**
 * Clears the persistent storage. This includes pending writes and cached
 * documents.
 *
 * Must be called while the `Firestore` instance is not started (after the app is
 * terminated or when the app is first initialized). On startup, this function
 * must be called before other functions (other than {@link
 * initializeFirestore} or {@link getFirestore})). If the `Firestore`
 * instance is still running, the promise will be rejected with the error code
 * of `failed-precondition`.
 *
 * Note: `clearIndexedDbPersistence()` is primarily intended to help write
 * reliable tests that use Cloud Firestore. It uses an efficient mechanism for
 * dropping existing data but does not attempt to securely overwrite or
 * otherwise make cached data unrecoverable. For applications that are sensitive
 * to the disclosure of cached data in between user sessions, we strongly
 * recommend not enabling persistence at all.
 *
 * @param firestore - The `Firestore` instance to clear persistence for.
 * @returns A promise that is resolved when the persistent storage is
 * cleared. Otherwise, the promise is rejected with an error.
 */
export declare function clearIndexedDbPersistence(
  firestore: FirebaseFirestore
): Promise<void>;

/**
 * A randomly-generated key assigned to each Firestore instance at startup.
 */
declare type ClientId = string;

/**
 * Gets a `CollectionReference` instance that refers to the collection at
 * the specified absolute path.
 *
 * @param firestore - A reference to the root Firestore instance.
 * @param path - A slash-separated path to a collection.
 * @param pathSegments - Additional path segments to apply relative to the first
 * argument.
 * @throws If the final path has an even number of segments and does not point
 * to a collection.
 * @returns The `CollectionReference` instance.
 */
export declare function collection(
  firestore: FirebaseFirestore_2,
  path: string,
  ...pathSegments: string[]
): CollectionReference<DocumentData>;

/**
 * Gets a `CollectionReference` instance that refers to a subcollection of
 * `reference` at the the specified relative path.
 *
 * @param reference - A reference to a collection.
 * @param path - A slash-separated path to a collection.
 * @param pathSegments - Additional path segments to apply relative to the first
 * argument.
 * @throws If the final path has an even number of segments and does not point
 * to a collection.
 * @returns The `CollectionReference` instance.
 */
export declare function collection(
  reference: CollectionReference<unknown>,
  path: string,
  ...pathSegments: string[]
): CollectionReference<DocumentData>;

/**
 * Gets a `CollectionReference` instance that refers to a subcollection of
 * `reference` at the the specified relative path.
 *
 * @param reference - A reference to a Firestore document.
 * @param path - A slash-separated path to a collection.
 * @param pathSegments - Additional path segments that will be applied relative
 * to the first argument.
 * @throws If the final path has an even number of segments and does not point
 * to a collection.
 * @returns The `CollectionReference` instance.
 */
export declare function collection(
  reference: DocumentReference,
  path: string,
  ...pathSegments: string[]
): CollectionReference<DocumentData>;

/**
 * Creates and returns a new `Query` instance that includes all documents in the
 * database that are contained in a collection or subcollection with the
 * given `collectionId`.
 *
 * @param firestore - A reference to the root Firestore instance.
 * @param collectionId - Identifies the collections to query over. Every
 * collection or subcollection with this ID as the last segment of its path
 * will be included. Cannot contain a slash.
 * @returns The created `Query`.
 */
export declare function collectionGroup(
  firestore: FirebaseFirestore_2,
  collectionId: string
): Query<DocumentData>;

/**
 * A `CollectionReference` object can be used for adding documents, getting
 * document references, and querying for documents (using {@link query}).
 */
export declare class CollectionReference<T = DocumentData> extends Query<T> {
  readonly firestore: FirebaseFirestore_2;
  readonly _path: ResourcePath;
  readonly type = 'collection';
  /** @hideconstructor */
  constructor(
    firestore: FirebaseFirestore_2,
    converter: FirestoreDataConverter_2<T> | null,
    _path: ResourcePath
  );
  /** The collection's identifier. */
  get id(): string;
  /**
   * A string representing the path of the referenced collection (relative
   * to the root of the database).
   */
  get path(): string;
  /**
   * A reference to the containing `DocumentReference` if this is a
   * subcollection. If this isn't a subcollection, the reference is null.
   */
  get parent(): DocumentReference<DocumentData> | null;
  /**
   * Applies a custom data converter to this CollectionReference, allowing you
   * to use your own custom model objects with Firestore. When you call {@link
   * addDoc} with the returned `CollectionReference` instance, the provided
   * converter will convert between Firestore data and your custom type `U`.
   *
   * @param converter - Converts objects to and from Firestore.
   * @returns A `CollectionReference<U>` that uses the provided converter.
   */
  withConverter<U>(
    converter: FirestoreDataConverter_2<U>
  ): CollectionReference<U>;
}

/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
declare type Comparator<K> = (key1: K, key2: K) => number;

declare interface ComponentConfiguration {
  asyncQueue: AsyncQueue;
  databaseInfo: DatabaseInfo;
  credentials: CredentialsProvider;
  clientId: ClientId;
  initialUser: User;
  maxConcurrentLimboResolutions: number;
}

declare type CompositeFilterOp = 'OPERATOR_UNSPECIFIED' | 'AND';

/**
 * A Listener for credential change events. The listener should fetch a new
 * token and may need to invalidate other state if the current user has also
 * changed.
 */
declare type CredentialChangeListener = (user: User) => void;

/**
 * Provides methods for getting the uid and token for the current user and
 * listening for changes.
 */
declare interface CredentialsProvider {
  /** Requests a token for the current user. */
  getToken(): Promise<Token | null>;
  /**
   * Marks the last retrieved token as invalid, making the next GetToken request
   * force-refresh the token.
   */
  invalidateToken(): void;
  /**
   * Specifies a listener to be notified of credential changes
   * (sign-in / sign-out, token changes). It is immediately called once with the
   * initial user.
   */
  setChangeListener(changeListener: CredentialChangeListener): void;
  /** Removes the previously-set change listener. */
  removeChangeListener(): void;
}

/** Settings for private credentials */
declare type CredentialsSettings =
  | FirstPartyCredentialsSettings
  | ProviderCredentialsSettings;

/** Represents the database ID a Firestore client is associated with. */
declare class DatabaseId {
  readonly projectId: string;
  readonly database: string;
  constructor(projectId: string, database?: string);
  get isDefaultDatabase(): boolean;
  isEqual(other: {}): boolean;
}

/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
declare class DatabaseInfo {
  readonly databaseId: DatabaseId;
  readonly persistenceKey: string;
  readonly host: string;
  readonly ssl: boolean;
  readonly forceLongPolling: boolean;
  readonly autoDetectLongPolling: boolean;
  /**
   * Constructs a DatabaseInfo using the provided host, databaseId and
   * persistenceKey.
   *
   * @param databaseId - The database to use.
   * @param persistenceKey - A unique identifier for this Firestore's local
   * storage (used in conjunction with the databaseId).
   * @param host - The Firestore backend host to connect to.
   * @param ssl - Whether to use SSL when connecting.
   * @param forceLongPolling - Whether to use the forceLongPolling option
   * when using WebChannel as the network transport.
   * @param autoDetectLongPolling - Whether to use the detectBufferingProxy
   * option when using WebChannel as the network transport.
   */
  constructor(
    databaseId: DatabaseId,
    persistenceKey: string,
    host: string,
    ssl: boolean,
    forceLongPolling: boolean,
    autoDetectLongPolling: boolean
  );
}

/**
 * Datastore and its related methods are a wrapper around the external Google
 * Cloud Datastore grpc API, which provides an interface that is more convenient
 * for the rest of the client SDK architecture to consume.
 */
declare abstract class Datastore {
  abstract terminate(): void;
}

/**
 * Represents an operation scheduled to be run in the future on an AsyncQueue.
 *
 * It is created via DelayedOperation.createAndSchedule().
 *
 * Supports cancellation (via cancel()) and early execution (via skipDelay()).
 *
 * Note: We implement `PromiseLike` instead of `Promise`, as the `Promise` type
 * in newer versions of TypeScript defines `finally`, which is not available in
 * IE.
 */
declare class DelayedOperation<T extends unknown> implements PromiseLike<T> {
  private readonly asyncQueue;
  readonly timerId: TimerId;
  readonly targetTimeMs: number;
  private readonly op;
  private readonly removalCallback;
  private timerHandle;
  private readonly deferred;
  private constructor();
  /**
   * Creates and returns a DelayedOperation that has been scheduled to be
   * executed on the provided asyncQueue after the provided delayMs.
   *
   * @param asyncQueue - The queue to schedule the operation on.
   * @param id - A Timer ID identifying the type of operation this is.
   * @param delayMs - The delay (ms) before the operation should be scheduled.
   * @param op - The operation to run.
   * @param removalCallback - A callback to be called synchronously once the
   *   operation is executed or canceled, notifying the AsyncQueue to remove it
   *   from its delayedOperations list.
   *   PORTING NOTE: This exists to prevent making removeDelayedOperation() and
   *   the DelayedOperation class public.
   */
  static createAndSchedule<R extends unknown>(
    asyncQueue: AsyncQueue,
    timerId: TimerId,
    delayMs: number,
    op: () => Promise<R>,
    removalCallback: (op: DelayedOperation<R>) => void
  ): DelayedOperation<R>;
  /**
   * Starts the timer. This is called immediately after construction by
   * createAndSchedule().
   */
  private start;
  /**
   * Queues the operation to run immediately (if it hasn't already been run or
   * canceled).
   */
  skipDelay(): void;
  /**
   * Cancels the operation if it hasn't already been executed or canceled. The
   * promise will be rejected.
   *
   * As long as the operation has not yet been run, calling cancel() provides a
   * guarantee that the operation will not be run.
   */
  cancel(reason?: string): void;
  then: <TResult1 = T, TResult2 = never>(
    onfulfilled?:
      | ((value: T) => TResult1 | PromiseLike<TResult1>)
      | null
      | undefined,
    onrejected?:
      | ((reason: any) => TResult2 | PromiseLike<TResult2>)
      | null
      | undefined
  ) => Promise<TResult1 | TResult2>;
  private handleDelayElapsed;
  private clearTimeout;
}

/**
 * Deletes the document referred to by the specified `DocumentReference`.
 *
 * @param reference - A reference to the document to delete.
 * @returns A Promise resolved once the document has been successfully
 * deleted from the backend (note that it won't resolve while you're offline).
 */
export declare function deleteDoc(
  reference: DocumentReference<unknown>
): Promise<void>;

/**
 * Returns a sentinel for use with {@link updateDoc} or
 * {@link setDoc} with `{merge: true}` to mark a field for deletion.
 */
export declare function deleteField(): FieldValue;

/**
 * The direction of sorting in an order by.
 */
declare const enum Direction {
  ASCENDING = 'asc',
  DESCENDING = 'desc'
}

/**
 * Disables network usage for this instance. It can be re-enabled via {@link
 * enableNetwork}. While the network is disabled, any snapshot listeners,
 * `getDoc()` or `getDocs()` calls will return results from cache, and any write
 * operations will be queued until the network is restored.
 *
 * @returns A promise that is resolved once the network has been disabled.
 */
export declare function disableNetwork(
  firestore: FirebaseFirestore
): Promise<void>;

/**
 * Gets a `DocumentReference` instance that refers to the document at the
 * specified abosulute path.
 *
 * @param firestore - A reference to the root Firestore instance.
 * @param path - A slash-separated path to a document.
 * @param pathSegments - Additional path segments that will be applied relative
 * to the first argument.
 * @throws If the final path has an odd number of segments and does not point to
 * a document.
 * @returns The `DocumentReference` instance.
 */
export declare function doc(
  firestore: FirebaseFirestore_2,
  path: string,
  ...pathSegments: string[]
): DocumentReference<DocumentData>;

/**
 * Gets a `DocumentReference` instance that refers to a document within
 * `reference` at the specified relative path. If no path is specified, an
 * automatically-generated unique ID will be used for the returned
 * `DocumentReference`.
 *
 * @param reference - A reference to a collection.
 * @param path - A slash-separated path to a document. Has to be omitted to use
 * auto-genrated IDs.
 * @param pathSegments - Additional path segments that will be applied relative
 * to the first argument.
 * @throws If the final path has an odd number of segments and does not point to
 * a document.
 * @returns The `DocumentReference` instance.
 */
export declare function doc<T>(
  reference: CollectionReference<T>,
  path?: string,
  ...pathSegments: string[]
): DocumentReference<T>;

/**
 * Gets a `DocumentReference` instance that refers to a document within
 * `reference` at the specified relative path.
 *
 * @param reference - A reference to a Firestore document.
 * @param path - A slash-separated path to a document.
 * @param pathSegments - Additional path segments that will be applied relative
 * to the first argument.
 * @throws If the final path has an odd number of segments and does not point to
 * a document.
 * @returns The `DocumentReference` instance.
 */
export declare function doc(
  reference: DocumentReference<unknown>,
  path: string,
  ...pathSegments: string[]
): DocumentReference<DocumentData>;

/**
 * Represents a document in Firestore with a key, version, data and whether the
 * data has local mutations applied to it.
 */
declare class Document_2 extends MaybeDocument {
  private readonly objectValue;
  readonly hasLocalMutations: boolean;
  readonly hasCommittedMutations: boolean;
  constructor(
    key: DocumentKey,
    version: SnapshotVersion,
    objectValue: ObjectValue,
    options: DocumentOptions
  );
  field(path: FieldPath_2): Value | null;
  data(): ObjectValue;
  toProto(): {
    mapValue: MapValue;
  };
  isEqual(other: MaybeDocument | null | undefined): boolean;
  toString(): string;
  get hasPendingWrites(): boolean;
}

/**
 * A `DocumentChange` represents a change to the documents matching a query.
 * It contains the document affected and the type of change that occurred.
 */
export declare interface DocumentChange<T = DocumentData> {
  /** The type of change ('added', 'modified', or 'removed'). */
  readonly type: DocumentChangeType;
  /** The document affected by this change. */
  readonly doc: QueryDocumentSnapshot<T>;
  /**
   * The index of the changed document in the result set immediately prior to
   * this `DocumentChange` (i.e. supposing that all prior `DocumentChange` objects
   * have been applied). Is `-1` for 'added' events.
   */
  readonly oldIndex: number;
  /**
   * The index of the changed document in the result set immediately after
   * this `DocumentChange` (i.e. supposing that all prior `DocumentChange`
   * objects and the current `DocumentChange` object have been applied).
   * Is -1 for 'removed' events.
   */
  readonly newIndex: number;
}

/**
 * The type of a `DocumentChange` may be 'added', 'removed', or 'modified'.
 */
export declare type DocumentChangeType = 'added' | 'removed' | 'modified';

declare type DocumentComparator = (
  doc1: Document_2,
  doc2: Document_2
) => number;

/**
 * Document data (for use with {@link setDoc}) consists of fields mapped to
 * values.
 */
export declare interface DocumentData {
  [field: string]: any;
}

/**
 * Returns a special sentinel `FieldPath` to refer to the ID of a document.
 * It can be used in queries to sort or filter by the document ID.
 */
export declare function documentId(): FieldPath;

declare class DocumentKey {
  readonly path: ResourcePath;
  constructor(path: ResourcePath);
  static fromPath(path: string): DocumentKey;
  static fromName(name: string): DocumentKey;
  /** Returns true if the document is in the specified collectionId. */
  hasCollectionId(collectionId: string): boolean;
  isEqual(other: DocumentKey | null): boolean;
  toString(): string;
  static comparator(k1: DocumentKey, k2: DocumentKey): number;
  static isDocumentKey(path: ResourcePath): boolean;
  /**
   * Creates and returns a new document key with the given segments.
   *
   * @param segments - The segments of the path to the document
   * @returns A new instance of DocumentKey
   */
  static fromSegments(segments: string[]): DocumentKey;
}

declare type DocumentKeySet = SortedSet<DocumentKey>;

declare type DocumentMap = SortedMap<DocumentKey, Document_2>;

declare interface DocumentOptions {
  hasLocalMutations?: boolean;
  hasCommittedMutations?: boolean;
}

/**
 * A `DocumentReference` refers to a document location in a Firestore database
 * and can be used to write, read, or listen to the location. The document at
 * the referenced location may or may not exist.
 */
export declare class DocumentReference<T = DocumentData> {
  readonly _converter: FirestoreDataConverter_2<T> | null;
  readonly _key: DocumentKey;
  /** The type of this Firestore reference. */
  readonly type = 'document';
  /**
   * The {@link FirebaseFirestore} the document is in.
   * This is useful for performing transactions, for example.
   */
  readonly firestore: FirebaseFirestore_2;
  /** @hideconstructor */
  constructor(
    firestore: FirebaseFirestore_2,
    _converter: FirestoreDataConverter_2<T> | null,
    _key: DocumentKey
  );
  get _path(): ResourcePath;
  /**
   * The document's identifier within its collection.
   */
  get id(): string;
  /**
   * A string representing the path of the referenced document (relative
   * to the root of the database).
   */
  get path(): string;
  /**
   * The collection this `DocumentReference` belongs to.
   */
  get parent(): CollectionReference<T>;
  /**
   * Applies a custom data converter to this `DocumentReference`, allowing you
   * to use your own custom model objects with Firestore. When you call {@link
   * setDoc}, {@link getDoc}, etc. with the returned `DocumentReference`
   * instance, the provided converter will convert between Firestore data and
   * your custom type `U`.
   *
   * @param converter - Converts objects to and from Firestore.
   * @returns A `DocumentReference<U>` that uses the provided converter.
   */
  withConverter<U>(
    converter: FirestoreDataConverter_2<U>
  ): DocumentReference<U>;
}

/**
 * DocumentSet is an immutable (copy-on-write) collection that holds documents
 * in order specified by the provided comparator. We always add a document key
 * comparator on top of what is provided to guarantee document equality based on
 * the key.
 */
declare class DocumentSet {
  /**
   * Returns an empty copy of the existing DocumentSet, using the same
   * comparator.
   */
  static emptySet(oldSet: DocumentSet): DocumentSet;
  private comparator;
  private keyedMap;
  private sortedSet;
  /** The default ordering is by key if the comparator is omitted */
  constructor(comp?: DocumentComparator);
  has(key: DocumentKey): boolean;
  get(key: DocumentKey): Document_2 | null;
  first(): Document_2 | null;
  last(): Document_2 | null;
  isEmpty(): boolean;
  /**
   * Returns the index of the provided key in the document set, or -1 if the
   * document key is not present in the set;
   */
  indexOf(key: DocumentKey): number;
  get size(): number;
  /** Iterates documents in order defined by "comparator" */
  forEach(cb: (doc: Document_2) => void): void;
  /** Inserts or updates a document with the same key */
  add(doc: Document_2): DocumentSet;
  /** Deletes a document with a given key */
  delete(key: DocumentKey): DocumentSet;
  isEqual(other: DocumentSet | null | undefined): boolean;
  toString(): string;
  private copy;
}

/**
 * A `DocumentSnapshot` contains data read from a document in your Firestore
 * database. The data can be extracted with `.data()` or `.get(<field>)` to
 * get a specific field.
 *
 * For a `DocumentSnapshot` that points to a non-existing document, any data
 * access will return 'undefined'. You can use the `exists()` method to
 * explicitly verify a document's existence.
 */
export declare class DocumentSnapshot<
  T = DocumentData
> extends DocumentSnapshot_2<T> {
  readonly _firestore: FirebaseFirestore;
  private readonly _firestoreImpl;
  /**
   *  Metadata about the `DocumentSnapshot`, including information about its
   *  source and local modifications.
   */
  readonly metadata: SnapshotMetadata;
  /** @hideconstructor protected */
  constructor(
    _firestore: FirebaseFirestore,
    userDataWriter: AbstractUserDataWriter,
    key: DocumentKey,
    document: Document_2 | null,
    metadata: SnapshotMetadata,
    converter: UntypedFirestoreDataConverter<T> | null
  );
  /**
   * Property of the `DocumentSnapshot` that signals whether or not the data
   * exists. True if the document exists.
   */
  exists(): this is QueryDocumentSnapshot<T>;
  /**
   * Retrieves all fields in the document as an `Object`. Returns `undefined` if
   * the document doesn't exist.
   *
   * By default, `FieldValue.serverTimestamp()` values that have not yet been
   * set to their final value will be returned as `null`. You can override
   * this by passing an options object.
   *
   * @param options - An options object to configure how data is retrieved from
   * the snapshot (for example the desired behavior for server timestamps that
   * have not yet been set to their final value).
   * @returns An `Object` containing all fields in the document or `undefined` if
   * the document doesn't exist.
   */
  data(options?: SnapshotOptions): T | undefined;
  /**
   * Retrieves the field specified by `fieldPath`. Returns `undefined` if the
   * document or field doesn't exist.
   *
   * By default, a `FieldValue.serverTimestamp()` that has not yet been set to
   * its final value will be returned as `null`. You can override this by
   * passing an options object.
   *
   * @param fieldPath - The path (for example 'foo' or 'foo.bar') to a specific
   * field.
   * @param options - An options object to configure how the field is retrieved
   * from the snapshot (for example the desired behavior for server timestamps
   * that have not yet been set to their final value).
   * @returns The data at the specified field location or undefined if no such
   * field exists in the document.
   */
  get(fieldPath: string | FieldPath, options?: SnapshotOptions): any;
}

/**
 * A `DocumentSnapshot` contains data read from a document in your Firestore
 * database. The data can be extracted with `.data()` or `.get(<field>)` to
 * get a specific field.
 *
 * For a `DocumentSnapshot` that points to a non-existing document, any data
 * access will return 'undefined'. You can use the `exists()` method to
 * explicitly verify a document's existence.
 */
declare class DocumentSnapshot_2<T = DocumentData> {
  _firestore: FirebaseFirestore_2;
  _userDataWriter: AbstractUserDataWriter;
  _key: DocumentKey;
  _document: Document_2 | null;
  _converter: UntypedFirestoreDataConverter<T> | null;
  /** @hideconstructor protected */
  constructor(
    _firestore: FirebaseFirestore_2,
    _userDataWriter: AbstractUserDataWriter,
    _key: DocumentKey,
    _document: Document_2 | null,
    _converter: UntypedFirestoreDataConverter<T> | null
  );
  /** Property of the `DocumentSnapshot` that provides the document's ID. */
  get id(): string;
  /**
   * The `DocumentReference` for the document included in the `DocumentSnapshot`.
   */
  get ref(): DocumentReference<T>;
  /**
   * Signals whether or not the document at the snapshot's location exists.
   *
   * @returns true if the document exists.
   */
  exists(): this is QueryDocumentSnapshot_2<T>;
  /**
   * Retrieves all fields in the document as an `Object`. Returns `undefined` if
   * the document doesn't exist.
   *
   * @returns An `Object` containing all fields in the document or `undefined`
   * if the document doesn't exist.
   */
  data(): T | undefined;
  /**
   * Retrieves the field specified by `fieldPath`. Returns `undefined` if the
   * document or field doesn't exist.
   *
   * @param fieldPath - The path (for example 'foo' or 'foo.bar') to a specific
   * field.
   * @returns The data at the specified field location or undefined if no such
   * field exists in the document.
   */
  get(fieldPath: string | FieldPath): any;
}

declare type DocumentVersionMap = SortedMap<DocumentKey, SnapshotVersion>;

declare interface DocumentViewChange {
  type: ChangeType;
  doc: Document_2;
}

/**
 * Attempts to enable persistent storage, if possible.
 *
 * Must be called before any other functions (other than
 * {@link initializeFirestore}, {@link getFirestore} or
 * {@link clearIndexedDbPersistence}.
 *
 * If this fails, `enableIndexedDbPersistence()` will reject the promise it
 * returns. Note that even after this failure, the `Firestore` instance will
 * remain usable, however offline persistence will be disabled.
 *
 * There are several reasons why this can fail, which can be identified by
 * the `code` on the error.
 *
 *   * failed-precondition: The app is already open in another browser tab.
 *   * unimplemented: The browser is incompatible with the offline
 *     persistence implementation.
 *
 * @param firestore - The `Firestore` instance to enable persistence for.
 * @param persistenceSettings - Optional settings object to configure
 * persistence.
 * @returns A promise that represents successfully enabling persistent storage.
 */
export declare function enableIndexedDbPersistence(
  firestore: FirebaseFirestore,
  persistenceSettings?: PersistenceSettings
): Promise<void>;

/**
 * Attempts to enable multi-tab persistent storage, if possible. If enabled
 * across all tabs, all operations share access to local persistence, including
 * shared execution of queries and latency-compensated local document updates
 * across all connected instances.
 *
 * If this fails, `enableMultiTabIndexedDbPersistence()` will reject the promise
 * it returns. Note that even after this failure, the `Firestore` instance will
 * remain usable, however offline persistence will be disabled.
 *
 * There are several reasons why this can fail, which can be identified by
 * the `code` on the error.
 *
 *   * failed-precondition: The app is already open in another browser tab and
 *     multi-tab is not enabled.
 *   * unimplemented: The browser is incompatible with the offline
 *     persistence implementation.
 *
 * @param firestore - The `Firestore` instance to enable persistence for.
 * @returns A promise that represents successfully enabling persistent
 * storage.
 */
export declare function enableMultiTabIndexedDbPersistence(
  firestore: FirebaseFirestore
): Promise<void>;

/**
 * Re-enables use of the network for this Firestore instance after a prior
 * call to {@link disableNetwork}.
 *
 * @returns A promise that is resolved once the network has been enabled.
 */
export declare function enableNetwork(
  firestore: FirebaseFirestore
): Promise<void>;

/**
 * Creates a `QueryConstraint` that modifies the result set to end at the
 * provided document (inclusive). The end position is relative to the order of
 * the query. The document must contain all of the fields provided in the
 * orderBy of the query.
 *
 * @param snapshot - The snapshot of the document to end at.
 * @returns A `QueryConstraint` to pass to `query()`
 */
export declare function endAt(
  snapshot: DocumentSnapshot_2<unknown>
): QueryConstraint;

/**
 * Creates a `QueryConstraint` that modifies the result set to end at the
 * provided fields relative to the order of the query. The order of the field
 * values must match the order of the order by clauses of the query.
 *
 * @param fieldValues - The field values to end this query at, in order
 * of the query's order by.
 * @returns A `QueryConstraint` to pass to `query()`
 */
export declare function endAt(...fieldValues: unknown[]): QueryConstraint;

/**
 * Creates a `QueryConstraint` that modifies the result set to end before the
 * provided document (exclusive). The end position is relative to the order of
 * the query. The document must contain all of the fields provided in the
 * orderBy of the query.
 *
 * @param snapshot - The snapshot of the document to end before.
 * @returns A `QueryConstraint` to pass to `query()`
 */
export declare function endBefore(
  snapshot: DocumentSnapshot_2<unknown>
): QueryConstraint;

/**
 * Creates a `QueryConstraint` that modifies the result set to end before the
 * provided fields relative to the order of the query. The order of the field
 * values must match the order of the order by clauses of the query.
 *
 * @param fieldValues - The field values to end this query before, in order
 * of the query's order by.
 * @returns A `QueryConstraint` to pass to `query()`
 */
export declare function endBefore(...fieldValues: unknown[]): QueryConstraint;

declare interface Entry<K, V> {
  key: K;
  value: V;
}

/**
 * EventManager is responsible for mapping queries to query event emitters.
 * It handles "fan-out". -- Identical queries will re-use the same watch on the
 * backend.
 *
 * PORTING NOTE: On Web, EventManager `onListen` and `onUnlisten` need to be
 * assigned to SyncEngine's `listen()` and `unlisten()` API before usage. This
 * allows users to tree-shake the Watch logic.
 */
declare interface EventManager {
  onListen?: (query: Query_2) => Promise<ViewSnapshot>;
  onUnlisten?: (query: Query_2) => Promise<void>;
}

declare type FieldFilterOp =
  | 'OPERATOR_UNSPECIFIED'
  | 'LESS_THAN'
  | 'LESS_THAN_OR_EQUAL'
  | 'GREATER_THAN'
  | 'GREATER_THAN_OR_EQUAL'
  | 'EQUAL'
  | 'NOT_EQUAL'
  | 'ARRAY_CONTAINS'
  | 'IN'
  | 'ARRAY_CONTAINS_ANY'
  | 'NOT_IN';

/**
 * Provides a set of fields that can be used to partially patch a document.
 * FieldMask is used in conjunction with ObjectValue.
 * Examples:
 *   foo - Overwrites foo entirely with the provided value. If foo is not
 *         present in the companion ObjectValue, the field is deleted.
 *   foo.bar - Overwrites only the field bar of the object foo.
 *             If foo is not an object, foo is replaced with an object
 *             containing foo
 */
declare class FieldMask {
  readonly fields: FieldPath_2[];
  constructor(fields: FieldPath_2[]);
  /**
   * Verifies that `fieldPath` is included by at least one field in this field
   * mask.
   *
   * This is an O(n) operation, where `n` is the size of the field mask.
   */
  covers(fieldPath: FieldPath_2): boolean;
  isEqual(other: FieldMask): boolean;
}

/**
 * A `FieldPath` refers to a field in a document. The path may consist of a
 * single field name (referring to a top-level field in the document), or a
 * list of field names (referring to a nested field in the document).
 *
 * Create a `FieldPath` by providing field names. If more than one field
 * name is provided, the path will point to a nested field in a document.
 */
export declare class FieldPath {
  /** Internal representation of a Firestore field path. */
  readonly _internalPath: FieldPath_2;
  /**
   * Creates a FieldPath from the provided field names. If more than one field
   * name is provided, the path will point to a nested field in a document.
   *
   * @param fieldNames - A list of field names.
   */
  constructor(...fieldNames: string[]);
  /**
   * Returns true if this `FieldPath` is equal to the provided one.
   *
   * @param other - The `FieldPath` to compare against.
   * @returns true if this `FieldPath` is equal to the provided one.
   */
  isEqual(other: FieldPath): boolean;
}

/** A dot-separated path for navigating sub-objects within a document. */
declare class FieldPath_2 extends BasePath<FieldPath_2> {
  protected construct(
    segments: string[],
    offset?: number,
    length?: number
  ): FieldPath_2;
  /**
   * Returns true if the string could be used as a segment in a field path
   * without escaping.
   */
  private static isValidIdentifier;
  canonicalString(): string;
  toString(): string;
  /**
   * Returns true if this field references the key of a document.
   */
  isKeyField(): boolean;
  /**
   * The field designating the key of a document.
   */
  static keyField(): FieldPath_2;
  /**
   * Parses a field string from the given server-formatted string.
   *
   * - Splitting the empty string is not allowed (for now at least).
   * - Empty segments within the string (e.g. if there are two consecutive
   *   separators) are not allowed.
   *
   * TODO(b/37244157): we should make this more strict. Right now, it allows
   * non-identifier path components, even if they aren't escaped.
   */
  static fromServerFormat(path: string): FieldPath_2;
  static emptyPath(): FieldPath_2;
}

/** A field path and the TransformOperation to perform upon it. */
declare class FieldTransform {
  readonly field: FieldPath_2;
  readonly transform: TransformOperation;
  constructor(field: FieldPath_2, transform: TransformOperation);
}

declare type FieldTransformSetToServerValue =
  | 'SERVER_VALUE_UNSPECIFIED'
  | 'REQUEST_TIME';

/**
 * Sentinel values that can be used when writing document fields with `set()`
 * or `update()`.
 */
export declare abstract class FieldValue {
  _methodName: string;
  /**
   * @param _methodName - The public API endpoint that returns this class.
   */
  constructor(_methodName: string);
  abstract isEqual(other: FieldValue): boolean;
  abstract _toFieldTransform(context: ParseContext): FieldTransform | null;
}

declare abstract class Filter {
  abstract matches(doc: Document_2): boolean;
}

/**
 * The Cloud Firestore service interface.
 *
 * Do not call this constructor directly. Instead, use {@link getFirestore}.
 */
export declare class FirebaseFirestore extends FirebaseFirestore_2 {
  readonly _queue: AsyncQueue;
  readonly _persistenceKey: string;
  _firestoreClient: FirestoreClient | undefined;
  /** @hideconstructor */
  constructor(
    databaseIdOrApp: DatabaseId | FirebaseApp,
    authProvider: Provider<FirebaseAuthInternalName>
  );
  _terminate(): Promise<void>;
}

/**
 * The Cloud Firestore service interface.
 *
 * Do not call this constructor directly. Instead, use {@link getFirestore}.
 */
declare class FirebaseFirestore_2 implements FirestoreService {
  readonly _databaseId: DatabaseId;
  readonly _persistenceKey: string;
  _credentials: CredentialsProvider;
  private _settings;
  private _settingsFrozen;
  private _terminateTask?;
  private _app?;
  /** @hideconstructor */
  constructor(
    databaseIdOrApp: DatabaseId | FirebaseApp,
    authProvider: Provider<FirebaseAuthInternalName>
  );
  /**
   * The {@link FirebaseApp} associated with this `Firestore` service
   * instance.
   */
  get app(): FirebaseApp;
  get _initialized(): boolean;
  get _terminated(): boolean;
  _setSettings(settings: PrivateSettings): void;
  _getSettings(): FirestoreSettings;
  _freezeSettings(): FirestoreSettings;
  _delete(): Promise<void>;
  toJSON(): object;
  /**
   * Terminates all components used by this client. Subclasses can override
   * this method to clean up their own dependencies, but must also call this
   * method.
   *
   * Only ever called once.
   */
  protected _terminate(): Promise<void>;
}

/**
 * FirestoreClient is a top-level class that constructs and owns all of the
 * pieces of the client SDK architecture. It is responsible for creating the
 * async queue that is shared by all of the other components in the system.
 */
declare class FirestoreClient {
  private credentials;
  /**
   * Asynchronous queue responsible for all of our internal processing. When
   * we get incoming work from the user (via public API) or the network
   * (incoming GRPC messages), we should always schedule onto this queue.
   * This ensures all of our work is properly serialized (e.g. we don't
   * start processing a new operation while the previous one is waiting for
   * an async I/O to complete).
   */
  asyncQueue: AsyncQueue;
  private databaseInfo;
  private user;
  private readonly clientId;
  private credentialListener;
  private readonly receivedInitialUser;
  offlineComponents?: OfflineComponentProvider;
  onlineComponents?: OnlineComponentProvider;
  constructor(
    credentials: CredentialsProvider,
    /**
     * Asynchronous queue responsible for all of our internal processing. When
     * we get incoming work from the user (via public API) or the network
     * (incoming GRPC messages), we should always schedule onto this queue.
     * This ensures all of our work is properly serialized (e.g. we don't
     * start processing a new operation while the previous one is waiting for
     * an async I/O to complete).
     */
    asyncQueue: AsyncQueue,
    databaseInfo: DatabaseInfo
  );
  getConfiguration(): Promise<ComponentConfiguration>;
  setCredentialChangeListener(listener: (user: User) => void): void;
  /**
   * Checks that the client has not been terminated. Ensures that other methods on
   * this class cannot be called after the client is terminated.
   */
  verifyNotTerminated(): void;
  terminate(): Promise<void>;
}

/**
 * Converter used by `withConverter()` to transform user objects of type `T`
 * into Firestore data.
 *
 * Using the converter allows you to specify generic type arguments when
 * storing and retrieving objects from Firestore.
 *
 * @example
 * ```typescript
 * class Post {
 *   constructor(readonly title: string, readonly author: string) {}
 *
 *   toString(): string {
 *     return this.title + ', by ' + this.author;
 *   }
 * }
 *
 * const postConverter = {
 *   toFirestore(post: Post): firebase.firestore.DocumentData {
 *     return {title: post.title, author: post.author};
 *   },
 *   fromFirestore(
 *     snapshot: firebase.firestore.QueryDocumentSnapshot,
 *     options: firebase.firestore.SnapshotOptions
 *   ): Post {
 *     const data = snapshot.data(options)!;
 *     return new Post(data.title, data.author);
 *   }
 * };
 *
 * const postSnap = await firebase.firestore()
 *   .collection('posts')
 *   .withConverter(postConverter)
 *   .doc().get();
 * const post = postSnap.data();
 * if (post !== undefined) {
 *   post.title; // string
 *   post.toString(); // Should be defined
 *   post.someNonExistentProperty; // TS error
 * }
 * ```
 */
export declare interface FirestoreDataConverter<T>
  extends FirestoreDataConverter_2<T> {
  /**
   * Called by the Firestore SDK to convert a custom model object of type `T`
   * into a plain JavaScript object (suitable for writing directly to the
   * Firestore database). To use `set()` with `merge` and `mergeFields`,
   * `toFirestore()` must be defined with `Partial<T>`.
   */
  toFirestore(modelObject: T): DocumentData;
  /**
   * Called by the Firestore SDK to convert a custom model object of type `T`
   * into a plain JavaScript object (suitable for writing directly to the
   * Firestore database). Used with {@link setData}, {@link WriteBatch#set}
   * and {@link Transaction#set} with `merge:true` or `mergeFields`.
   */
  toFirestore(modelObject: Partial<T>, options: SetOptions): DocumentData;
  /**
   * Called by the Firestore SDK to convert Firestore data into an object of
   * type T. You can access your data by calling: `snapshot.data(options)`.
   *
   * @param snapshot - A `QueryDocumentSnapshot` containing your data and metadata.
   * @param options - The `SnapshotOptions` from the initial call to `data()`.
   */
  fromFirestore(
    snapshot: QueryDocumentSnapshot<DocumentData>,
    options?: SnapshotOptions
  ): T;
}

/**
 * Converter used by `withConverter()` to transform user objects of type `T`
 * into Firestore data.
 *
 * Using the converter allows you to specify generic type arguments when
 * storing and retrieving objects from Firestore.
 *
 * @example
 * ```typescript
 * class Post {
 *   constructor(readonly title: string, readonly author: string) {}
 *
 *   toString(): string {
 *     return this.title + ', by ' + this.author;
 *   }
 * }
 *
 * const postConverter = {
 *   toFirestore(post: Post): firebase.firestore.DocumentData {
 *     return {title: post.title, author: post.author};
 *   },
 *   fromFirestore(snapshot: firebase.firestore.QueryDocumentSnapshot): Post {
 *     const data = snapshot.data(options)!;
 *     return new Post(data.title, data.author);
 *   }
 * };
 *
 * const postSnap = await firebase.firestore()
 *   .collection('posts')
 *   .withConverter(postConverter)
 *   .doc().get();
 * const post = postSnap.data();
 * if (post !== undefined) {
 *   post.title; // string
 *   post.toString(); // Should be defined
 *   post.someNonExistentProperty; // TS error
 * }
 * ```
 */
declare interface FirestoreDataConverter_2<T> {
  /**
   * Called by the Firestore SDK to convert a custom model object of type `T`
   * into a plain Javascript object (suitable for writing directly to the
   * Firestore database). Used with {@link setData}, {@link WriteBatch#set}
   * and {@link Transaction#set}.
   */
  toFirestore(modelObject: T): DocumentData;
  /**
   * Called by the Firestore SDK to convert a custom model object of type `T`
   * into a plain Javascript object (suitable for writing directly to the
   * Firestore database). Used with {@link setData}, {@link WriteBatch#set}
   * and {@link Transaction#set} with `merge:true` or `mergeFields`.
   */
  toFirestore(modelObject: Partial<T>, options: SetOptions): DocumentData;
  /**
   * Called by the Firestore SDK to convert Firestore data into an object of
   * type T. You can access your data by calling: `snapshot.data()`.
   *
   * @param snapshot - A `QueryDocumentSnapshot` containing your data and
   * metadata.
   */
  fromFirestore(snapshot: QueryDocumentSnapshot_2<DocumentData>): T;
}

/** An error returned by a Firestore operation. */
export declare class FirestoreError extends Error {
  readonly code: FirestoreErrorCode;
  readonly message: string;
  readonly name: string;
  readonly stack?: string;
  /** @hideconstructor */
  constructor(code: FirestoreErrorCode, message: string);
}

/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
/**
 * The set of Firestore status codes. The codes are the same at the ones
 * exposed by gRPC here:
 * https://github.com/grpc/grpc/blob/master/doc/statuscodes.md
 *
 * Possible values:
 * - 'cancelled': The operation was cancelled (typically by the caller).
 * - 'unknown': Unknown error or an error from a different error domain.
 * - 'invalid-argument': Client specified an invalid argument. Note that this
 *   differs from 'failed-precondition'. 'invalid-argument' indicates
 *   arguments that are problematic regardless of the state of the system
 *   (e.g. an invalid field name).
 * - 'deadline-exceeded': Deadline expired before operation could complete.
 *   For operations that change the state of the system, this error may be
 *   returned even if the operation has completed successfully. For example,
 *   a successful response from a server could have been delayed long enough
 *   for the deadline to expire.
 * - 'not-found': Some requested document was not found.
 * - 'already-exists': Some document that we attempted to create already
 *   exists.
 * - 'permission-denied': The caller does not have permission to execute the
 *   specified operation.
 * - 'resource-exhausted': Some resource has been exhausted, perhaps a
 *   per-user quota, or perhaps the entire file system is out of space.
 * - 'failed-precondition': Operation was rejected because the system is not
 *   in a state required for the operation's execution.
 * - 'aborted': The operation was aborted, typically due to a concurrency
 *   issue like transaction aborts, etc.
 * - 'out-of-range': Operation was attempted past the valid range.
 * - 'unimplemented': Operation is not implemented or not supported/enabled.
 * - 'internal': Internal errors. Means some invariants expected by
 *   underlying system has been broken. If you see one of these errors,
 *   something is very broken.
 * - 'unavailable': The service is currently unavailable. This is most likely
 *   a transient condition and may be corrected by retrying with a backoff.
 * - 'data-loss': Unrecoverable data loss or corruption.
 * - 'unauthenticated': The request does not have valid authentication
 *   credentials for the operation.
 */
export declare type FirestoreErrorCode =
  | 'cancelled'
  | 'unknown'
  | 'invalid-argument'
  | 'deadline-exceeded'
  | 'not-found'
  | 'already-exists'
  | 'permission-denied'
  | 'resource-exhausted'
  | 'failed-precondition'
  | 'aborted'
  | 'out-of-range'
  | 'unimplemented'
  | 'internal'
  | 'unavailable'
  | 'data-loss'
  | 'unauthenticated';

/**
 * An interface implemented by FirebaseFirestore that provides compatibility
 * with the usage in this file.
 *
 * This interface mainly exists to remove a cyclic dependency.
 */
declare interface FirestoreService extends _FirebaseService {
  _credentials: CredentialsProvider;
  _persistenceKey: string;
  _databaseId: DatabaseId;
  _terminated: boolean;
  _freezeSettings(): FirestoreSettings;
}

/**
 * A concrete type describing all the values that can be applied via a
 * user-supplied firestore.Settings object. This is a separate type so that
 * defaults can be supplied and the value can be checked for equality.
 */
declare class FirestoreSettings {
  /** The hostname to connect to. */
  readonly host: string;
  /** Whether to use SSL when connecting. */
  readonly ssl: boolean;
  readonly cacheSizeBytes: number;
  readonly experimentalForceLongPolling: boolean;
  readonly experimentalAutoDetectLongPolling: boolean;
  readonly ignoreUndefinedProperties: boolean;
  credentials?: any;
  constructor(settings: PrivateSettings);
  isEqual(other: FirestoreSettings): boolean;
}

declare namespace firestoreV1ApiClientInterfaces {
  interface ArrayValue {
    values?: Value[];
  }
  interface BatchGetDocumentsRequest {
    database?: string;
    documents?: string[];
    mask?: DocumentMask;
    transaction?: string;
    newTransaction?: TransactionOptions;
    readTime?: string;
  }
  interface BatchGetDocumentsResponse {
    found?: Document;
    missing?: string;
    transaction?: string;
    readTime?: string;
  }
  interface BeginTransactionRequest {
    options?: TransactionOptions;
  }
  interface BeginTransactionResponse {
    transaction?: string;
  }
  interface CollectionSelector {
    collectionId?: string;
    allDescendants?: boolean;
  }
  interface CommitRequest {
    database?: string;
    writes?: Write[];
    transaction?: string;
  }
  interface CommitResponse {
    writeResults?: WriteResult[];
    commitTime?: string;
  }
  interface CompositeFilter {
    op?: CompositeFilterOp;
    filters?: Filter[];
  }
  interface Cursor {
    values?: Value[];
    before?: boolean;
  }
  interface Document {
    name?: string;
    fields?: ApiClientObjectMap<Value>;
    createTime?: Timestamp_2;
    updateTime?: Timestamp_2;
  }
  interface DocumentChange {
    document?: Document;
    targetIds?: number[];
    removedTargetIds?: number[];
  }
  interface DocumentDelete {
    document?: string;
    removedTargetIds?: number[];
    readTime?: Timestamp_2;
  }
  interface DocumentMask {
    fieldPaths?: string[];
  }
  interface DocumentRemove {
    document?: string;
    removedTargetIds?: number[];
    readTime?: string;
  }
  interface DocumentTransform {
    document?: string;
    fieldTransforms?: FieldTransform[];
  }
  interface DocumentsTarget {
    documents?: string[];
  }
  interface Empty {}
  interface ExistenceFilter {
    targetId?: number;
    count?: number;
  }
  interface FieldFilter {
    field?: FieldReference;
    op?: FieldFilterOp;
    value?: Value;
  }
  interface FieldReference {
    fieldPath?: string;
  }
  interface FieldTransform {
    fieldPath?: string;
    setToServerValue?: FieldTransformSetToServerValue;
    appendMissingElements?: ArrayValue;
    removeAllFromArray?: ArrayValue;
    increment?: Value;
  }
  interface Filter {
    compositeFilter?: CompositeFilter;
    fieldFilter?: FieldFilter;
    unaryFilter?: UnaryFilter;
  }
  interface Index {
    name?: string;
    collectionId?: string;
    fields?: IndexField[];
    state?: IndexState;
  }
  interface IndexField {
    fieldPath?: string;
    mode?: IndexFieldMode;
  }
  interface LatLng {
    latitude?: number;
    longitude?: number;
  }
  interface ListCollectionIdsRequest {
    pageSize?: number;
    pageToken?: string;
  }
  interface ListCollectionIdsResponse {
    collectionIds?: string[];
    nextPageToken?: string;
  }
  interface ListDocumentsResponse {
    documents?: Document[];
    nextPageToken?: string;
  }
  interface ListIndexesResponse {
    indexes?: Index[];
    nextPageToken?: string;
  }
  interface ListenRequest {
    addTarget?: Target;
    removeTarget?: number;
    labels?: ApiClientObjectMap<string>;
  }
  interface ListenResponse {
    targetChange?: TargetChange;
    documentChange?: DocumentChange;
    documentDelete?: DocumentDelete;
    documentRemove?: DocumentRemove;
    filter?: ExistenceFilter;
  }
  interface MapValue {
    fields?: ApiClientObjectMap<Value>;
  }
  interface Operation {
    name?: string;
    metadata?: ApiClientObjectMap<any>;
    done?: boolean;
    error?: Status;
    response?: ApiClientObjectMap<any>;
  }
  interface Order {
    field?: FieldReference;
    direction?: OrderDirection;
  }
  interface Precondition {
    exists?: boolean;
    updateTime?: Timestamp_2;
  }
  interface Projection {
    fields?: FieldReference[];
  }
  interface QueryTarget {
    parent?: string;
    structuredQuery?: StructuredQuery;
  }
  interface ReadOnly {
    readTime?: string;
  }
  interface ReadWrite {
    retryTransaction?: string;
  }
  interface RollbackRequest {
    transaction?: string;
  }
  interface RunQueryRequest {
    parent?: string;
    structuredQuery?: StructuredQuery;
    transaction?: string;
    newTransaction?: TransactionOptions;
    readTime?: string;
  }
  interface RunQueryResponse {
    transaction?: string;
    document?: Document;
    readTime?: string;
    skippedResults?: number;
  }
  interface Status {
    code?: number;
    message?: string;
    details?: Array<ApiClientObjectMap<any>>;
  }
  interface StructuredQuery {
    select?: Projection;
    from?: CollectionSelector[];
    where?: Filter;
    orderBy?: Order[];
    startAt?: Cursor;
    endAt?: Cursor;
    offset?: number;
    limit?:
      | number
      | {
          value: number;
        };
  }
  interface Target {
    query?: QueryTarget;
    documents?: DocumentsTarget;
    resumeToken?: string | Uint8Array;
    readTime?: Timestamp_2;
    targetId?: number;
    once?: boolean;
  }
  interface TargetChange {
    targetChangeType?: TargetChangeTargetChangeType;
    targetIds?: number[];
    cause?: Status;
    resumeToken?: string | Uint8Array;
    readTime?: Timestamp_2;
  }
  interface TransactionOptions {
    readOnly?: ReadOnly;
    readWrite?: ReadWrite;
  }
  interface UnaryFilter {
    op?: UnaryFilterOp;
    field?: FieldReference;
  }
  interface Value {
    nullValue?: ValueNullValue;
    booleanValue?: boolean;
    integerValue?: string | number;
    doubleValue?: string | number;
    timestampValue?: Timestamp_2;
    stringValue?: string;
    bytesValue?: string | Uint8Array;
    referenceValue?: string;
    geoPointValue?: LatLng;
    arrayValue?: ArrayValue;
    mapValue?: MapValue;
  }
  interface Write {
    update?: Document;
    delete?: string;
    verify?: string;
    transform?: DocumentTransform;
    updateMask?: DocumentMask;
    updateTransforms?: FieldTransform[];
    currentDocument?: Precondition;
  }
  interface WriteRequest {
    streamId?: string;
    writes?: Write[];
    streamToken?: string | Uint8Array;
    labels?: ApiClientObjectMap<string>;
  }
  interface WriteResponse {
    streamId?: string;
    streamToken?: string | Uint8Array;
    writeResults?: WriteResult[];
    commitTime?: Timestamp_2;
  }
  interface WriteResult {
    updateTime?: Timestamp_2;
    transformResults?: Value[];
  }
}

declare interface FirstPartyCredentialsSettings {
  ['type']: 'gapi';
  ['client']: unknown;
  ['sessionIndex']: string;
}

/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
declare type FulfilledHandler<T, R> =
  | ((result: T) => R | PersistencePromise<R>)
  | null;

/**
 * Interface implemented by the LRU scheduler to start(), stop() and restart
 * garbage collection.
 */
declare interface GarbageCollectionScheduler {
  readonly started: boolean;
  start(localStore: LocalStore): void;
  stop(): void;
}

/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
/**
 * An immutable object representing a geographic location in Firestore. The
 * location is represented as latitude/longitude pair.
 *
 * Latitude values are in the range of [-90, 90].
 * Longitude values are in the range of [-180, 180].
 */
export declare class GeoPoint {
  private _lat;
  private _long;
  /**
   * Creates a new immutable `GeoPoint` object with the provided latitude and
   * longitude values.
   * @param latitude - The latitude as number between -90 and 90.
   * @param longitude - The longitude as number between -180 and 180.
   */
  constructor(latitude: number, longitude: number);
  /**
   * The latitude of this `GeoPoint` instance.
   */
  get latitude(): number;
  /**
   * The longitude of this `GeoPoint` instance.
   */
  get longitude(): number;
  /**
   * Returns true if this `GeoPoint` is equal to the provided one.
   *
   * @param other - The `GeoPoint` to compare against.
   * @returns true if this `GeoPoint` is equal to the provided one.
   */
  isEqual(other: GeoPoint): boolean;
  toJSON(): {
    latitude: number;
    longitude: number;
  };
  /**
   * Actually private to JS consumers of our API, so this function is prefixed
   * with an underscore.
   */
  _compareTo(other: GeoPoint): number;
}

/**
 * Reads the document referred to by this `DocumentReference`.
 *
 * Note: `getDoc()` attempts to provide up-to-date data when possible by waiting
 * for data from the server, but it may return cached data or fail if you are
 * offline and the server cannot be reached. To specify this behavior, invoke
 * {@link getDocFromCache} or {@link getDocFromServer}.
 *
 * @param reference - The reference of the document to fetch.
 * @returns A Promise resolved with a `DocumentSnapshot` containing the
 * current document contents.
 */
export declare function getDoc<T>(
  reference: DocumentReference<T>
): Promise<DocumentSnapshot<T>>;

/**
 * Reads the document referred to by this `DocumentReference` from cache.
 * Returns an error if the document is not currently cached.
 *
 * @returns A Promise resolved with a `DocumentSnapshot` containing the
 * current document contents.
 */
export declare function getDocFromCache<T>(
  reference: DocumentReference<T>
): Promise<DocumentSnapshot<T>>;

/**
 * Reads the document referred to by this `DocumentReference` from the server.
 * Returns an error if the network is not available.
 *
 * @returns A Promise resolved with a `DocumentSnapshot` containing the
 * current document contents.
 */
export declare function getDocFromServer<T>(
  reference: DocumentReference<T>
): Promise<DocumentSnapshot<T>>;

/**
 * Executes the query and returns the results as a `QuerySnapshot`.
 *
 * Note: `getDocs()` attempts to provide up-to-date data when possible by
 * waiting for data from the server, but it may return cached data or fail if
 * you are offline and the server cannot be reached. To specify this behavior,
 * invoke {@link getDocsFromCache} or {@link getDocsFromServer}.
 *
 * @returns A Promise that will be resolved with the results of the query.
 */
export declare function getDocs<T>(query: Query<T>): Promise<QuerySnapshot<T>>;

/**
 * Executes the query and returns the results as a `QuerySnapshot` from cache.
 * Returns an error if the document is not currently cached.
 *
 * @returns A Promise that will be resolved with the results of the query.
 */
export declare function getDocsFromCache<T>(
  query: Query<T>
): Promise<QuerySnapshot<T>>;

/**
 * Executes the query and returns the results as a `QuerySnapshot` from the
 * server. Returns an error if the network is not available.
 *
 * @returns A Promise that will be resolved with the results of the query.
 */
export declare function getDocsFromServer<T>(
  query: Query<T>
): Promise<QuerySnapshot<T>>;

/**
 * Returns the existing instance of Firestore that is associated with the
 * provided {@link FirebaseApp}. If no instance exists, initializes a new
 * instance with default settings.
 *
 * @param app - The {@link FirebaseApp} instance that the returned Firestore
 * instance is associated with.
 * @returns The `Firestore` instance of the provided app.
 */
export declare function getFirestore(app: FirebaseApp): FirebaseFirestore;

/**
 * Returns a special value that can be used with {@link setDoc} or {@link
 * updateDoc} that tells the server to increment the field's current value by
 * the given value.
 *
 * If either the operand or the current field value uses floating point
 * precision, all arithmetic follows IEEE 754 semantics. If both values are
 * integers, values outside of JavaScript's safe number range
 * (`Number.MIN_SAFE_INTEGER` to `Number.MAX_SAFE_INTEGER`) are also subject to
 * precision loss. Furthermore, once processed by the Firestore backend, all
 * integer operations are capped between -2^63 and 2^63-1.
 *
 * If the current field value is not of type `number`, or if the field does not
 * yet exist, the transformation sets the field to the given value.
 *
 * @param n - The value to increment by.
 * @returns The `FieldValue` sentinel for use in a call to `setDoc()` or
 * `updateDoc()`
 */
export declare function increment(n: number): FieldValue;

declare type IndexFieldMode = 'MODE_UNSPECIFIED' | 'ASCENDING' | 'DESCENDING';

/**
 * Represents a set of indexes that are used to execute queries efficiently.
 *
 * Currently the only index is a [collection id] =&gt; [parent path] index, used
 * to execute Collection Group queries.
 */
declare interface IndexManager {
  /**
   * Creates an index entry mapping the collectionId (last segment of the path)
   * to the parent path (either the containing document location or the empty
   * path for root-level collections). Index entries can be retrieved via
   * getCollectionParents().
   *
   * NOTE: Currently we don't remove index entries. If this ends up being an
   * issue we can devise some sort of GC strategy.
   */
  addToCollectionParentIndex(
    transaction: PersistenceTransaction,
    collectionPath: ResourcePath
  ): PersistencePromise<void>;
  /**
   * Retrieves all parent locations containing the given collectionId, as a
   * list of paths (each path being either a document location or the empty
   * path for a root-level collection).
   */
  getCollectionParents(
    transaction: PersistenceTransaction,
    collectionId: string
  ): PersistencePromise<ResourcePath[]>;
}

declare type IndexState = 'STATE_UNSPECIFIED' | 'CREATING' | 'READY' | 'ERROR';

/**
 * Initializes a new instance of Cloud Firestore with the provided settings.
 * Can only be called before any other function, including
 * {@link getFirestore}. If the custom settings are empty, this function is
 * equivalent to calling {@link getFirestore}.
 *
 * @param app - The {@link FirebaseApp} with which the `Firestore` instance will
 * be associated.
 * @param settings - A settings object to configure the `Firestore` instance.
 * @returns A newly initialized `Firestore` instance.
 */
export declare function initializeFirestore(
  app: FirebaseApp,
  settings: Settings
): FirebaseFirestore;

/**
 * Creates a `QueryConstraint` that only returns the first matching documents.
 *
 * @param limit - The maximum number of items to return.
 * @returns The created `Query`.
 */
export declare function limit(limit: number): QueryConstraint;

/**
 * Creates a `QueryConstraint` that only returns the last matching documents.
 *
 * You must specify at least one `orderBy` clause for `limitToLast` queries,
 * otherwise an exception will be thrown during execution.
 *
 * @param limit - The maximum number of items to return.
 * @returns The created `Query`.
 */
export declare function limitToLast(limit: number): QueryConstraint;

declare const enum LimitType {
  First = 'F',
  Last = 'L'
}

/** LimitType enum. */
declare type LimitType_2 = 'FIRST' | 'LAST';

declare type ListenSequenceNumber = number;

declare class LLRBEmptyNode<K, V> {
  get key(): never;
  get value(): never;
  get color(): never;
  get left(): never;
  get right(): never;
  size: number;
  copy(
    key: K | null,
    value: V | null,
    color: boolean | null,
    left: LLRBNode<K, V> | LLRBEmptyNode<K, V> | null,
    right: LLRBNode<K, V> | LLRBEmptyNode<K, V> | null
  ): LLRBEmptyNode<K, V>;
  insert(key: K, value: V, comparator: Comparator<K>): LLRBNode<K, V>;
  remove(key: K, comparator: Comparator<K>): LLRBEmptyNode<K, V>;
  isEmpty(): boolean;
  inorderTraversal(action: (k: K, v: V) => boolean): boolean;
  reverseTraversal(action: (k: K, v: V) => boolean): boolean;
  minKey(): K | null;
  maxKey(): K | null;
  isRed(): boolean;
  checkMaxDepth(): boolean;
  protected check(): 0;
}

declare class LLRBNode<K, V> {
  key: K;
  value: V;
  readonly color: boolean;
  readonly left: LLRBNode<K, V> | LLRBEmptyNode<K, V>;
  readonly right: LLRBNode<K, V> | LLRBEmptyNode<K, V>;
  readonly size: number;
  static EMPTY: LLRBEmptyNode<any, any>;
  static RED: boolean;
  static BLACK: boolean;
  constructor(
    key: K,
    value: V,
    color?: boolean,
    left?: LLRBNode<K, V> | LLRBEmptyNode<K, V>,
    right?: LLRBNode<K, V> | LLRBEmptyNode<K, V>
  );
  copy(
    key: K | null,
    value: V | null,
    color: boolean | null,
    left: LLRBNode<K, V> | LLRBEmptyNode<K, V> | null,
    right: LLRBNode<K, V> | LLRBEmptyNode<K, V> | null
  ): LLRBNode<K, V>;
  isEmpty(): boolean;
  inorderTraversal<T>(action: (k: K, v: V) => T): T;
  reverseTraversal<T>(action: (k: K, v: V) => T): T;
  private min;
  minKey(): K | null;
  maxKey(): K | null;
  insert(key: K, value: V, comparator: Comparator<K>): LLRBNode<K, V>;
  private removeMin;
  remove(
    key: K,
    comparator: Comparator<K>
  ): LLRBNode<K, V> | LLRBEmptyNode<K, V>;
  isRed(): boolean;
  private fixUp;
  private moveRedLeft;
  private moveRedRight;
  private rotateLeft;
  private rotateRight;
  private colorFlip;
  checkMaxDepth(): boolean;
  protected check(): number;
}

/**
 * Loads a Firestore bundle into the local cache.
 *
 * @param firestore - The `Firestore` instance to load bundles for for.
 * @param bundleData - An object representing the bundle to be loaded. Valid objects are
 *   `ArrayBuffer`, `ReadableStream<Uint8Array>` or `string`.
 *
 * @return
 *   A `LoadBundleTask` object, which notifies callers with progress updates, and completion
 *   or error events. It can be used as a `Promise<LoadBundleTaskProgress>`.
 */
export declare function loadBundle(
  firestore: FirebaseFirestore,
  bundleData: ReadableStream<Uint8Array> | ArrayBuffer | string
): LoadBundleTask;

/**
 * Represents the task of loading a Firestore bundle. It provides progress of bundle
 * loading, as well as task completion and error events.
 *
 * The API is compatible with `Promise<LoadBundleTaskProgress>`.
 */
export declare class LoadBundleTask
  implements PromiseLike<LoadBundleTaskProgress> {
  private _progressObserver;
  private _taskCompletionResolver;
  private _lastProgress;
  /**
   * Registers functions to listen to bundle loading progress events.
   * @param next - Called when there is a progress update from bundle loading. Typically `next` calls occur
   *   each time a Firestore document is loaded from the bundle.
   * @param error - Called when an error occurs during bundle loading. The task aborts after reporting the
   *   error, and there should be no more updates after this.
   * @param complete - Called when the loading task is complete.
   */
  onProgress(
    next?: (progress: LoadBundleTaskProgress) => unknown,
    error?: (err: Error) => unknown,
    complete?: () => void
  ): void;
  /**
   * Implements the `Promise<LoadBundleTaskProgress>.catch` interface.
   *
   * @param onRejected - Called when an error occurs during bundle loading.
   */
  catch<R>(
    onRejected: (a: Error) => R | PromiseLike<R>
  ): Promise<R | LoadBundleTaskProgress>;
  /**
   * Implements the `Promise<LoadBundleTaskProgress>.then` interface.
   *
   * @param onFulfilled - Called on the completion of the loading task with a final `LoadBundleTaskProgress` update.
   *   The update will always have its `taskState` set to `"Success"`.
   * @param onRejected - Called when an error occurs during bundle loading.
   */
  then<T, R>(
    onFulfilled?: (a: LoadBundleTaskProgress) => T | PromiseLike<T>,
    onRejected?: (a: Error) => R | PromiseLike<R>
  ): Promise<T | R>;
  /**
   * Notifies all observers that bundle loading has completed, with a provided
   * `LoadBundleTaskProgress` object.
   *
   * @private
   */
  _completeWith(progress: LoadBundleTaskProgress): void;
  /**
   * Notifies all observers that bundle loading has failed, with a provided
   * `Error` as the reason.
   *
   * @private
   */
  _failWith(error: FirestoreError): void;
  /**
   * Notifies a progress update of loading a bundle.
   * @param progress - The new progress.
   *
   * @private
   */
  _updateProgress(progress: LoadBundleTaskProgress): void;
}

/**
 * Represents a progress update or a final state from loading bundles.
 */
export declare interface LoadBundleTaskProgress {
  /** How many documents have been loaded. */
  documentsLoaded: number;
  /** How many documents are in the bundle being loaded. */
  totalDocuments: number;
  /** How many bytes have been loaded. */
  bytesLoaded: number;
  /** How many bytes are in the bundle being loaded. */
  totalBytes: number;
  /** Current task state. */
  taskState: TaskState;
}

declare interface LocalStore {
  collectGarbage(garbageCollector: LruGarbageCollector): Promise<LruResults>;
}
export { LogLevel };

declare interface LruGarbageCollector {
  readonly params: LruParams;
  collect(
    txn: PersistenceTransaction,
    activeTargetIds: ActiveTargets
  ): PersistencePromise<LruResults>;
  /** Given a percentile of target to collect, returns the number of targets to collect. */
  calculateTargetCount(
    txn: PersistenceTransaction,
    percentile: number
  ): PersistencePromise<number>;
  /** Returns the nth sequence number, counting in order from the smallest. */
  nthSequenceNumber(
    txn: PersistenceTransaction,
    n: number
  ): PersistencePromise<number>;
  /**
   * Removes documents that have a sequence number equal to or less than the
   * upper bound and are not otherwise pinned.
   */
  removeOrphanedDocuments(
    txn: PersistenceTransaction,
    upperBound: ListenSequenceNumber
  ): PersistencePromise<number>;
  getCacheSize(txn: PersistenceTransaction): PersistencePromise<number>;
  /**
   * Removes targets with a sequence number equal to or less than the given
   * upper bound, and removes document associations with those targets.
   */
  removeTargets(
    txn: PersistenceTransaction,
    upperBound: ListenSequenceNumber,
    activeTargetIds: ActiveTargets
  ): PersistencePromise<number>;
}

declare class LruParams {
  readonly cacheSizeCollectionThreshold: number;
  readonly percentileToCollect: number;
  readonly maximumSequenceNumbersToCollect: number;
  private static readonly DEFAULT_COLLECTION_PERCENTILE;
  private static readonly DEFAULT_MAX_SEQUENCE_NUMBERS_TO_COLLECT;
  static withCacheSize(cacheSize: number): LruParams;
  static readonly DEFAULT: LruParams;
  static readonly DISABLED: LruParams;
  constructor(
    cacheSizeCollectionThreshold: number,
    percentileToCollect: number,
    maximumSequenceNumbersToCollect: number
  );
}

/**
 * Describes the results of a garbage collection run. `didRun` will be set to
 * `false` if collection was skipped (either it is disabled or the cache size
 * has not hit the threshold). If collection ran, the other fields will be
 * filled in with the details of the results.
 */
declare interface LruResults {
  readonly didRun: boolean;
  readonly sequenceNumbersCollected: number;
  readonly targetsRemoved: number;
  readonly documentsRemoved: number;
}

declare type MapValue = firestoreV1ApiClientInterfaces.MapValue;

/**
 * The result of a lookup for a given path may be an existing document or a
 * marker that this document does not exist at a given version.
 */
declare abstract class MaybeDocument {
  readonly key: DocumentKey;
  readonly version: SnapshotVersion;
  constructor(key: DocumentKey, version: SnapshotVersion);
  /**
   * Whether this document had a local mutation applied that has not yet been
   * acknowledged by Watch.
   */
  abstract get hasPendingWrites(): boolean;
  abstract isEqual(other: MaybeDocument | null | undefined): boolean;
  abstract toString(): string;
}

declare type MaybeDocumentMap = SortedMap<DocumentKey, MaybeDocument>;

/**
 * A mutation describes a self-contained change to a document. Mutations can
 * create, replace, delete, and update subsets of documents.
 *
 * Mutations not only act on the value of the document but also its version.
 *
 * For local mutations (mutations that haven't been committed yet), we preserve
 * the existing version for Set and Patch mutations. For Delete mutations, we
 * reset the version to 0.
 *
 * Here's the expected transition table.
 *
 * MUTATION           APPLIED TO            RESULTS IN
 *
 * SetMutation        Document(v3)          Document(v3)
 * SetMutation        NoDocument(v3)        Document(v0)
 * SetMutation        null                  Document(v0)
 * PatchMutation      Document(v3)          Document(v3)
 * PatchMutation      NoDocument(v3)        NoDocument(v3)
 * PatchMutation      null                  null
 * DeleteMutation     Document(v3)          NoDocument(v0)
 * DeleteMutation     NoDocument(v3)        NoDocument(v0)
 * DeleteMutation     null                  NoDocument(v0)
 *
 * For acknowledged mutations, we use the updateTime of the WriteResponse as
 * the resulting version for Set and Patch mutations. As deletes have no
 * explicit update time, we use the commitTime of the WriteResponse for
 * Delete mutations.
 *
 * If a mutation is acknowledged by the backend but fails the precondition check
 * locally, we return an `UnknownDocument` and rely on Watch to send us the
 * updated version.
 *
 * Field transforms are used only with Patch and Set Mutations. We use the
 * `updateTransforms` message to store transforms, rather than the `transforms`s
 * messages.
 *
 * ## Subclassing Notes
 *
 * Subclasses of Mutation need to implement applyToRemoteDocument() and
 * applyToLocalView() to implement the actual behavior of applying the mutation
 * to some source document.
 */
declare abstract class Mutation {
  abstract readonly type: MutationType;
  abstract readonly key: DocumentKey;
  abstract readonly precondition: Precondition;
  abstract readonly fieldTransforms: FieldTransform[];
}

/**
 * A batch of mutations that will be sent as one unit to the backend.
 */
declare class MutationBatch {
  batchId: BatchId;
  localWriteTime: Timestamp;
  baseMutations: Mutation[];
  mutations: Mutation[];
  /**
   * @param batchId - The unique ID of this mutation batch.
   * @param localWriteTime - The original write time of this mutation.
   * @param baseMutations - Mutations that are used to populate the base
   * values when this mutation is applied locally. This can be used to locally
   * overwrite values that are persisted in the remote document cache. Base
   * mutations are never sent to the backend.
   * @param mutations - The user-provided mutations in this mutation batch.
   * User-provided mutations are applied both locally and remotely on the
   * backend.
   */
  constructor(
    batchId: BatchId,
    localWriteTime: Timestamp,
    baseMutations: Mutation[],
    mutations: Mutation[]
  );
  /**
   * Applies all the mutations in this MutationBatch to the specified document
   * to create a new remote document
   *
   * @param docKey - The key of the document to apply mutations to.
   * @param maybeDoc - The document to apply mutations to.
   * @param batchResult - The result of applying the MutationBatch to the
   * backend.
   */
  applyToRemoteDocument(
    docKey: DocumentKey,
    maybeDoc: MaybeDocument | null,
    batchResult: MutationBatchResult
  ): MaybeDocument | null;
  /**
   * Computes the local view of a document given all the mutations in this
   * batch.
   *
   * @param docKey - The key of the document to apply mutations to.
   * @param maybeDoc - The document to apply mutations to.
   */
  applyToLocalView(
    docKey: DocumentKey,
    maybeDoc: MaybeDocument | null
  ): MaybeDocument | null;
  /**
   * Computes the local view for all provided documents given the mutations in
   * this batch.
   */
  applyToLocalDocumentSet(maybeDocs: MaybeDocumentMap): MaybeDocumentMap;
  keys(): DocumentKeySet;
  isEqual(other: MutationBatch): boolean;
}

/** The result of applying a mutation batch to the backend. */
declare class MutationBatchResult {
  readonly batch: MutationBatch;
  readonly commitVersion: SnapshotVersion;
  readonly mutationResults: MutationResult[];
  /**
   * A pre-computed mapping from each mutated document to the resulting
   * version.
   */
  readonly docVersions: DocumentVersionMap;
  private constructor();
  /**
   * Creates a new MutationBatchResult for the given batch and results. There
   * must be one result for each mutation in the batch. This static factory
   * caches a document=&gt;version mapping (docVersions).
   */
  static from(
    batch: MutationBatch,
    commitVersion: SnapshotVersion,
    results: MutationResult[]
  ): MutationBatchResult;
}

/** A queue of mutations to apply to the remote store. */
declare interface MutationQueue {
  /** Returns true if this queue contains no mutation batches. */
  checkEmpty(transaction: PersistenceTransaction): PersistencePromise<boolean>;
  /**
   * Creates a new mutation batch and adds it to this mutation queue.
   *
   * @param transaction - The transaction this operation is scoped to.
   * @param localWriteTime - The original write time of this mutation.
   * @param baseMutations - Mutations that are used to populate the base values
   * when this mutation is applied locally. These mutations are used to locally
   * overwrite values that are persisted in the remote document cache.
   * @param mutations - The user-provided mutations in this mutation batch.
   */
  addMutationBatch(
    transaction: PersistenceTransaction,
    localWriteTime: Timestamp,
    baseMutations: Mutation[],
    mutations: Mutation[]
  ): PersistencePromise<MutationBatch>;
  /**
   * Loads the mutation batch with the given batchId.
   */
  lookupMutationBatch(
    transaction: PersistenceTransaction,
    batchId: BatchId
  ): PersistencePromise<MutationBatch | null>;
  /**
   * Gets the first unacknowledged mutation batch after the passed in batchId
   * in the mutation queue or null if empty.
   *
   * @param batchId - The batch to search after, or BATCHID_UNKNOWN for the
   * first mutation in the queue.
   *
   * @returns the next mutation or null if there wasn't one.
   */
  getNextMutationBatchAfterBatchId(
    transaction: PersistenceTransaction,
    batchId: BatchId
  ): PersistencePromise<MutationBatch | null>;
  /**
   * Gets the largest (latest) batch id in mutation queue for the current user
   * that is pending server response, returns `BATCHID_UNKNOWN` if the queue is
   * empty.
   *
   * @returns the largest batch id in the mutation queue that is not
   * acknowledged.
   */
  getHighestUnacknowledgedBatchId(
    transaction: PersistenceTransaction
  ): PersistencePromise<BatchId>;
  /** Gets all mutation batches in the mutation queue. */
  getAllMutationBatches(
    transaction: PersistenceTransaction
  ): PersistencePromise<MutationBatch[]>;
  /**
   * Finds all mutation batches that could possibly affect the given
   * document key. Not all mutations in a batch will necessarily affect the
   * document key, so when looping through the batch you'll need to check that
   * the mutation itself matches the key.
   *
   * Batches are guaranteed to be in sorted order.
   *
   * Note that because of this requirement implementations are free to return
   * mutation batches that don't contain the document key at all if it's
   * convenient.
   */
  getAllMutationBatchesAffectingDocumentKey(
    transaction: PersistenceTransaction,
    documentKey: DocumentKey
  ): PersistencePromise<MutationBatch[]>;
  /**
   * Finds all mutation batches that could possibly affect the given set of
   * document keys. Not all mutations in a batch will necessarily affect each
   * key, so when looping through the batch you'll need to check that the
   * mutation itself matches the key.
   *
   * Batches are guaranteed to be in sorted order.
   *
   * Note that because of this requirement implementations are free to return
   * mutation batches that don't contain any of the document keys at all if it's
   * convenient.
   */
  getAllMutationBatchesAffectingDocumentKeys(
    transaction: PersistenceTransaction,
    documentKeys: SortedMap<DocumentKey, unknown>
  ): PersistencePromise<MutationBatch[]>;
  /**
   * Finds all mutation batches that could affect the results for the given
   * query. Not all mutations in a batch will necessarily affect the query, so
   * when looping through the batch you'll need to check that the mutation
   * itself matches the query.
   *
   * Batches are guaranteed to be in sorted order.
   *
   * Note that because of this requirement implementations are free to return
   * mutation batches that don't match the query at all if it's convenient.
   *
   * NOTE: A PatchMutation does not need to include all fields in the query
   * filter criteria in order to be a match (but any fields it does contain do
   * need to match).
   */
  getAllMutationBatchesAffectingQuery(
    transaction: PersistenceTransaction,
    query: Query_2
  ): PersistencePromise<MutationBatch[]>;
  /**
   * Removes the given mutation batch from the queue. This is useful in two
   * circumstances:
   *
   * + Removing an applied mutation from the head of the queue
   * + Removing a rejected mutation from anywhere in the queue
   *
   * Multi-Tab Note: This operation should only be called by the primary client.
   */
  removeMutationBatch(
    transaction: PersistenceTransaction,
    batch: MutationBatch
  ): PersistencePromise<void>;
  /**
   * Performs a consistency check, examining the mutation queue for any
   * leaks, if possible.
   */
  performConsistencyCheck(
    transaction: PersistenceTransaction
  ): PersistencePromise<void>;
}

/** The result of successfully applying a mutation to the backend. */
declare class MutationResult {
  /**
   * The version at which the mutation was committed:
   *
   * - For most operations, this is the updateTime in the WriteResult.
   * - For deletes, the commitTime of the WriteResponse (because deletes are
   *   not stored and have no updateTime).
   *
   * Note that these versions can be different: No-op writes will not change
   * the updateTime even though the commitTime advances.
   */
  readonly version: SnapshotVersion;
  /**
   * The resulting fields returned from the backend after a mutation
   * containing field transforms has been committed. Contains one FieldValue
   * for each FieldTransform that was in the mutation.
   *
   * Will be null if the mutation did not contain any field transforms.
   */
  readonly transformResults: Array<Value | null> | null;
  constructor(
    /**
     * The version at which the mutation was committed:
     *
     * - For most operations, this is the updateTime in the WriteResult.
     * - For deletes, the commitTime of the WriteResponse (because deletes are
     *   not stored and have no updateTime).
     *
     * Note that these versions can be different: No-op writes will not change
     * the updateTime even though the commitTime advances.
     */
    version: SnapshotVersion,
    /**
     * The resulting fields returned from the backend after a mutation
     * containing field transforms has been committed. Contains one FieldValue
     * for each FieldTransform that was in the mutation.
     *
     * Will be null if the mutation did not contain any field transforms.
     */
    transformResults: Array<Value | null> | null
  );
}

declare const enum MutationType {
  Set = 0,
  Patch = 1,
  Delete = 2,
  Verify = 3
}

/**
 * Represents a Query saved by the SDK in its local storage.
 */
declare interface NamedQuery {
  /** The name of the query. */
  readonly name: string;
  /** The underlying query associated with `name`. */
  readonly query: Query_2;
  /** The time at which the results for this query were read. */
  readonly readTime: SnapshotVersion;
}

/**
 * Reads a Firestore `Query` from local cache, identified by the given name.
 *
 * The named queries are packaged  into bundles on the server side (along
 * with resulting documents), and loaded to local cache using `loadBundle`. Once in local
 * cache, use this method to extract a `Query` by name.
 */
export declare function namedQuery(
  firestore: FirebaseFirestore,
  name: string
): Promise<Query | null>;

/** Properties of a NamedQuery. */
declare interface NamedQuery_2 {
  /** NamedQuery name */
  name?: string | null;
  /** NamedQuery bundledQuery */
  bundledQuery?: BundledQuery | null;
  /** NamedQuery readTime */
  readTime?: Timestamp_2 | null;
}

declare type NullableMaybeDocumentMap = SortedMap<
  DocumentKey,
  MaybeDocument | null
>;

/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
/**
 * A map implementation that uses objects as keys. Objects must have an
 * associated equals function and must be immutable. Entries in the map are
 * stored together with the key being produced from the mapKeyFn. This map
 * automatically handles collisions of keys.
 */
declare class ObjectMap<KeyType, ValueType> {
  private mapKeyFn;
  private equalsFn;
  /**
   * The inner map for a key/value pair. Due to the possibility of collisions we
   * keep a list of entries that we do a linear search through to find an actual
   * match. Note that collisions should be rare, so we still expect near
   * constant time lookups in practice.
   */
  private inner;
  constructor(
    mapKeyFn: (key: KeyType) => string,
    equalsFn: (l: KeyType, r: KeyType) => boolean
  );
  /** Get a value for this key, or undefined if it does not exist. */
  get(key: KeyType): ValueType | undefined;
  has(key: KeyType): boolean;
  /** Put this key and value in the map. */
  set(key: KeyType, value: ValueType): void;
  /**
   * Remove this key from the map. Returns a boolean if anything was deleted.
   */
  delete(key: KeyType): boolean;
  forEach(fn: (key: KeyType, val: ValueType) => void): void;
  isEmpty(): boolean;
}

/**
 * An ObjectValue represents a MapValue in the Firestore Proto and offers the
 * ability to add and remove fields (via the ObjectValueBuilder).
 */
declare class ObjectValue {
  readonly proto: {
    mapValue: MapValue;
  };
  constructor(proto: { mapValue: MapValue });
  static empty(): ObjectValue;
  /**
   * Returns the value at the given path or null.
   *
   * @param path - the path to search
   * @returns The value at the path or if there it doesn't exist.
   */
  field(path: FieldPath_2): Value | null;
  isEqual(other: ObjectValue): boolean;
}

/**
 * Initializes and wires components that are needed to interface with the local
 * cache. Implementations override `initialize()` to provide all components.
 */
declare interface OfflineComponentProvider {
  persistence: Persistence;
  sharedClientState: SharedClientState;
  localStore: LocalStore;
  gcScheduler: GarbageCollectionScheduler | null;
  synchronizeTabs: boolean;
  initialize(cfg: ComponentConfiguration): Promise<void>;
  terminate(): Promise<void>;
}

/**
 * Initializes and wires the components that are needed to interface with the
 * network.
 */
declare class OnlineComponentProvider {
  protected localStore: LocalStore;
  protected sharedClientState: SharedClientState;
  datastore: Datastore;
  eventManager: EventManager;
  remoteStore: RemoteStore;
  syncEngine: SyncEngine;
  initialize(
    offlineComponentProvider: OfflineComponentProvider,
    cfg: ComponentConfiguration
  ): Promise<void>;
  createEventManager(cfg: ComponentConfiguration): EventManager;
  createDatastore(cfg: ComponentConfiguration): Datastore;
  createRemoteStore(cfg: ComponentConfiguration): RemoteStore;
  createSyncEngine(
    cfg: ComponentConfiguration,
    startAsPrimary: boolean
  ): SyncEngine;
  terminate(): Promise<void>;
}

/**
 * Describes the online state of the Firestore client. Note that this does not
 * indicate whether or not the remote store is trying to connect or not. This is
 * primarily used by the View / EventManager code to change their behavior while
 * offline (e.g. get() calls shouldn't wait for data from the server and
 * snapshot events should set metadata.isFromCache=true).
 *
 * The string values should not be changed since they are persisted in
 * WebStorage.
 */
declare const enum OnlineState {
  /**
   * The Firestore client is in an unknown online state. This means the client
   * is either not actively trying to establish a connection or it is currently
   * trying to establish a connection, but it has not succeeded or failed yet.
   * Higher-level components should not operate in offline mode.
   */
  Unknown = 'Unknown',
  /**
   * The client is connected and the connections are healthy. This state is
   * reached after a successful connection and there has been at least one
   * successful message received from the backends.
   */
  Online = 'Online',
  /**
   * The client is either trying to establish a connection but failing, or it
   * has been explicitly marked offline via a call to disableNetwork().
   * Higher-level components should operate in offline mode.
   */
  Offline = 'Offline'
}

/**
 * Attaches a listener for `DocumentSnapshot` events. You may either pass
 * individual `onNext` and `onError` callbacks or pass a single observer
 * object with `next` and `error` callbacks.
 *
 * NOTE: Although an `onCompletion` callback can be provided, it will
 * never be called because the snapshot stream is never-ending.
 *
 * @param reference - A reference to the document to listen to.
 * @param observer - A single object containing `next` and `error` callbacks.
 * @returns An unsubscribe function that can be called to cancel
 * the snapshot listener.
 */
export declare function onSnapshot<T>(
  reference: DocumentReference<T>,
  observer: {
    next?: (snapshot: DocumentSnapshot<T>) => void;
    error?: (error: FirestoreError) => void;
    complete?: () => void;
  }
): Unsubscribe;

/**
 * Attaches a listener for `DocumentSnapshot` events. You may either pass
 * individual `onNext` and `onError` callbacks or pass a single observer
 * object with `next` and `error` callbacks.
 *
 * NOTE: Although an `onCompletion` callback can be provided, it will
 * never be called because the snapshot stream is never-ending.
 *
 * @param reference - A reference to the document to listen to.
 * @param options - Options controlling the listen behavior.
 * @param observer - A single object containing `next` and `error` callbacks.
 * @returns An unsubscribe function that can be called to cancel
 * the snapshot listener.
 */
export declare function onSnapshot<T>(
  reference: DocumentReference<T>,
  options: SnapshotListenOptions,
  observer: {
    next?: (snapshot: DocumentSnapshot<T>) => void;
    error?: (error: FirestoreError) => void;
    complete?: () => void;
  }
): Unsubscribe;

/**
 * Attaches a listener for `DocumentSnapshot` events. You may either pass
 * individual `onNext` and `onError` callbacks or pass a single observer
 * object with `next` and `error` callbacks.
 *
 * NOTE: Although an `onCompletion` callback can be provided, it will
 * never be called because the snapshot stream is never-ending.
 *
 * @param reference - A reference to the document to listen to.
 * @param onNext - A callback to be called every time a new `DocumentSnapshot`
 * is available.
 * @param onError - A callback to be called if the listen fails or is
 * cancelled. No further callbacks will occur.
 * @param onCompletion - Can be provided, but will not be called since streams are
 * never ending.
 * @returns An unsubscribe function that can be called to cancel
 * the snapshot listener.
 */
export declare function onSnapshot<T>(
  reference: DocumentReference<T>,
  onNext: (snapshot: DocumentSnapshot<T>) => void,
  onError?: (error: FirestoreError) => void,
  onCompletion?: () => void
): Unsubscribe;

/**
 * Attaches a listener for `DocumentSnapshot` events. You may either pass
 * individual `onNext` and `onError` callbacks or pass a single observer
 * object with `next` and `error` callbacks.
 *
 * NOTE: Although an `onCompletion` callback can be provided, it will
 * never be called because the snapshot stream is never-ending.
 *
 * @param reference - A reference to the document to listen to.
 * @param options - Options controlling the listen behavior.
 * @param onNext - A callback to be called every time a new `DocumentSnapshot`
 * is available.
 * @param onError - A callback to be called if the listen fails or is
 * cancelled. No further callbacks will occur.
 * @param onCompletion - Can be provided, but will not be called since streams are
 * never ending.
 * @returns An unsubscribe function that can be called to cancel
 * the snapshot listener.
 */
export declare function onSnapshot<T>(
  reference: DocumentReference<T>,
  options: SnapshotListenOptions,
  onNext: (snapshot: DocumentSnapshot<T>) => void,
  onError?: (error: FirestoreError) => void,
  onCompletion?: () => void
): Unsubscribe;

/**
 * Attaches a listener for `QuerySnapshot` events. You may either pass
 * individual `onNext` and `onError` callbacks or pass a single observer
 * object with `next` and `error` callbacks. The listener can be cancelled by
 * calling the function that is returned when `onSnapshot` is called.
 *
 * NOTE: Although an `onCompletion` callback can be provided, it will
 * never be called because the snapshot stream is never-ending.
 *
 * @param query - The query to listen to.
 * @param observer - A single object containing `next` and `error` callbacks.
 * @returns An unsubscribe function that can be called to cancel
 * the snapshot listener.
 */
export declare function onSnapshot<T>(
  query: Query<T>,
  observer: {
    next?: (snapshot: QuerySnapshot<T>) => void;
    error?: (error: FirestoreError) => void;
    complete?: () => void;
  }
): Unsubscribe;

/**
 * Attaches a listener for `QuerySnapshot` events. You may either pass
 * individual `onNext` and `onError` callbacks or pass a single observer
 * object with `next` and `error` callbacks. The listener can be cancelled by
 * calling the function that is returned when `onSnapshot` is called.
 *
 * NOTE: Although an `onCompletion` callback can be provided, it will
 * never be called because the snapshot stream is never-ending.
 *
 * @param query - The query to listen to.
 * @param options - Options controlling the listen behavior.
 * @param observer - A single object containing `next` and `error` callbacks.
 * @returns An unsubscribe function that can be called to cancel
 * the snapshot listener.
 */
export declare function onSnapshot<T>(
  query: Query<T>,
  options: SnapshotListenOptions,
  observer: {
    next?: (snapshot: QuerySnapshot<T>) => void;
    error?: (error: FirestoreError) => void;
    complete?: () => void;
  }
): Unsubscribe;

/**
 * Attaches a listener for `QuerySnapshot` events. You may either pass
 * individual `onNext` and `onError` callbacks or pass a single observer
 * object with `next` and `error` callbacks. The listener can be cancelled by
 * calling the function that is returned when `onSnapshot` is called.
 *
 * NOTE: Although an `onCompletion` callback can be provided, it will
 * never be called because the snapshot stream is never-ending.
 *
 * @param query - The query to listen to.
 * @param onNext - A callback to be called every time a new `QuerySnapshot`
 * is available.
 * @param onCompletion - Can be provided, but will not be called since streams are
 * never ending.
 * @param onError - A callback to be called if the listen fails or is
 * cancelled. No further callbacks will occur.
 * @returns An unsubscribe function that can be called to cancel
 * the snapshot listener.
 */
export declare function onSnapshot<T>(
  query: Query<T>,
  onNext: (snapshot: QuerySnapshot<T>) => void,
  onError?: (error: FirestoreError) => void,
  onCompletion?: () => void
): Unsubscribe;

/**
 * Attaches a listener for `QuerySnapshot` events. You may either pass
 * individual `onNext` and `onError` callbacks or pass a single observer
 * object with `next` and `error` callbacks. The listener can be cancelled by
 * calling the function that is returned when `onSnapshot` is called.
 *
 * NOTE: Although an `onCompletion` callback can be provided, it will
 * never be called because the snapshot stream is never-ending.
 *
 * @param query - The query to listen to.
 * @param options - Options controlling the listen behavior.
 * @param onNext - A callback to be called every time a new `QuerySnapshot`
 * is available.
 * @param onCompletion - Can be provided, but will not be called since streams are
 * never ending.
 * @param onError - A callback to be called if the listen fails or is
 * cancelled. No further callbacks will occur.
 * @returns An unsubscribe function that can be called to cancel
 * the snapshot listener.
 */
export declare function onSnapshot<T>(
  query: Query<T>,
  options: SnapshotListenOptions,
  onNext: (snapshot: QuerySnapshot<T>) => void,
  onError?: (error: FirestoreError) => void,
  onCompletion?: () => void
): Unsubscribe;

/**
 * Attaches a listener for a snapshots-in-sync event. The snapshots-in-sync
 * event indicates that all listeners affected by a given change have fired,
 * even if a single server-generated change affects multiple listeners.
 *
 * NOTE: The snapshots-in-sync event only indicates that listeners are in sync
 * with each other, but does not relate to whether those snapshots are in sync
 * with the server. Use SnapshotMetadata in the individual listeners to
 * determine if a snapshot is from the cache or the server.
 *
 * @param firestore - The instance of Firestore for synchronizing snapshots.
 * @param observer - A single object containing `next` and `error` callbacks.
 * @returns An unsubscribe function that can be called to cancel the snapshot
 * listener.
 */
export declare function onSnapshotsInSync(
  firestore: FirebaseFirestore,
  observer: {
    next?: (value: void) => void;
    error?: (error: FirestoreError) => void;
    complete?: () => void;
  }
): Unsubscribe;

/**
 * Attaches a listener for a snapshots-in-sync event. The snapshots-in-sync
 * event indicates that all listeners affected by a given change have fired,
 * even if a single server-generated change affects multiple listeners.
 *
 * NOTE: The snapshots-in-sync event only indicates that listeners are in sync
 * with each other, but does not relate to whether those snapshots are in sync
 * with the server. Use SnapshotMetadata in the individual listeners to
 * determine if a snapshot is from the cache or the server.
 *
 * @param firestore - The instance of Firestore for synchronizing snapshots.
 * @param onSync - A callback to be called every time all snapshot listeners are
 * in sync with each other.
 * @returns An unsubscribe function that can be called to cancel the snapshot
 * listener.
 */
export declare function onSnapshotsInSync(
  firestore: FirebaseFirestore,
  onSync: () => void
): Unsubscribe;

/**
 * An ordering on a field, in some Direction. Direction defaults to ASCENDING.
 */
declare class OrderBy {
  readonly field: FieldPath_2;
  readonly dir: Direction;
  constructor(field: FieldPath_2, dir?: Direction);
}

/**
 * Creates a `QueryConstraint` that sorts the query result by the
 * specified field, optionally in descending order instead of ascending.
 *
 * @param fieldPath - The field to sort by.
 * @param directionStr - Optional direction to sort by ('asc' or 'desc'). If
 * not specified, order will be ascending.
 * @returns The created `Query`.
 */
export declare function orderBy(
  fieldPath: string | FieldPath,
  directionStr?: OrderByDirection
): QueryConstraint;

/**
 * The direction of a {@link orderBy} clause is specified as 'desc' or 'asc'
 * (descending or ascending).
 */
export declare type OrderByDirection = 'desc' | 'asc';

declare type OrderDirection =
  | 'DIRECTION_UNSPECIFIED'
  | 'ASCENDING'
  | 'DESCENDING';

declare interface ParseContext {
  readonly databaseId: DatabaseId;
  readonly ignoreUndefinedProperties: boolean;
}

/** The result of parsing document data (e.g. for a setData call). */
declare class ParsedSetData {
  readonly data: ObjectValue;
  readonly fieldMask: FieldMask | null;
  readonly fieldTransforms: FieldTransform[];
  constructor(
    data: ObjectValue,
    fieldMask: FieldMask | null,
    fieldTransforms: FieldTransform[]
  );
  toMutation(key: DocumentKey, precondition: Precondition): Mutation;
}

/** The result of parsing "update" data (i.e. for an updateData call). */
declare class ParsedUpdateData {
  readonly data: ObjectValue;
  readonly fieldMask: FieldMask;
  readonly fieldTransforms: FieldTransform[];
  constructor(
    data: ObjectValue,
    fieldMask: FieldMask,
    fieldTransforms: FieldTransform[]
  );
  toMutation(key: DocumentKey, precondition: Precondition): Mutation;
}

/**
 * Persistence is the lowest-level shared interface to persistent storage in
 * Firestore.
 *
 * Persistence is used to create MutationQueue and RemoteDocumentCache
 * instances backed by persistence (which might be in-memory or LevelDB).
 *
 * Persistence also exposes an API to create and run PersistenceTransactions
 * against persistence. All read / write operations must be wrapped in a
 * transaction. Implementations of PersistenceTransaction / Persistence only
 * need to guarantee that writes made against the transaction are not made to
 * durable storage until the transaction resolves its PersistencePromise.
 * Since memory-only storage components do not alter durable storage, they are
 * free to ignore the transaction.
 *
 * This contract is enough to allow the LocalStore be be written
 * independently of whether or not the stored state actually is durably
 * persisted. If persistent storage is enabled, writes are grouped together to
 * avoid inconsistent state that could cause crashes.
 *
 * Concretely, when persistent storage is enabled, the persistent versions of
 * MutationQueue, RemoteDocumentCache, and others (the mutators) will
 * defer their writes into a transaction. Once the local store has completed
 * one logical operation, it commits the transaction.
 *
 * When persistent storage is disabled, the non-persistent versions of the
 * mutators ignore the transaction. This short-cut is allowed because
 * memory-only storage leaves no state so it cannot be inconsistent.
 *
 * This simplifies the implementations of the mutators and allows memory-only
 * implementations to supplement the persistent ones without requiring any
 * special dual-store implementation of Persistence. The cost is that the
 * LocalStore needs to be slightly careful about the order of its reads and
 * writes in order to avoid relying on being able to read back uncommitted
 * writes.
 */
declare interface Persistence {
  /**
   * Whether or not this persistence instance has been started.
   */
  readonly started: boolean;
  readonly referenceDelegate: ReferenceDelegate;
  /** Starts persistence. */
  start(): Promise<void>;
  /**
   * Releases any resources held during eager shutdown.
   */
  shutdown(): Promise<void>;
  /**
   * Registers a listener that gets called when the database receives a
   * version change event indicating that it has deleted.
   *
   * PORTING NOTE: This is only used for Web multi-tab.
   */
  setDatabaseDeletedListener(
    databaseDeletedListener: () => Promise<void>
  ): void;
  /**
   * Adjusts the current network state in the client's metadata, potentially
   * affecting the primary lease.
   *
   * PORTING NOTE: This is only used for Web multi-tab.
   */
  setNetworkEnabled(networkEnabled: boolean): void;
  /**
   * Returns a MutationQueue representing the persisted mutations for the
   * given user.
   *
   * Note: The implementation is free to return the same instance every time
   * this is called for a given user. In particular, the memory-backed
   * implementation does this to emulate the persisted implementation to the
   * extent possible (e.g. in the case of uid switching from
   * sally=&gt;jack=&gt;sally, sally's mutation queue will be preserved).
   */
  getMutationQueue(user: User): MutationQueue;
  /**
   * Returns a TargetCache representing the persisted cache of targets.
   *
   * Note: The implementation is free to return the same instance every time
   * this is called. In particular, the memory-backed implementation does this
   * to emulate the persisted implementation to the extent possible.
   */
  getTargetCache(): TargetCache;
  /**
   * Returns a RemoteDocumentCache representing the persisted cache of remote
   * documents.
   *
   * Note: The implementation is free to return the same instance every time
   * this is called. In particular, the memory-backed implementation does this
   * to emulate the persisted implementation to the extent possible.
   */
  getRemoteDocumentCache(): RemoteDocumentCache;
  /**
   * Returns a BundleCache representing the persisted cache of loaded bundles.
   *
   * Note: The implementation is free to return the same instance every time
   * this is called. In particular, the memory-backed implementation does this
   * to emulate the persisted implementation to the extent possible.
   */
  getBundleCache(): BundleCache;
  /**
   * Returns an IndexManager instance that manages our persisted query indexes.
   *
   * Note: The implementation is free to return the same instance every time
   * this is called. In particular, the memory-backed implementation does this
   * to emulate the persisted implementation to the extent possible.
   */
  getIndexManager(): IndexManager;
  /**
   * Performs an operation inside a persistence transaction. Any reads or writes
   * against persistence must be performed within a transaction. Writes will be
   * committed atomically once the transaction completes.
   *
   * Persistence operations are asynchronous and therefore the provided
   * transactionOperation must return a PersistencePromise. When it is resolved,
   * the transaction will be committed and the Promise returned by this method
   * will resolve.
   *
   * @param action - A description of the action performed by this transaction,
   * used for logging.
   * @param mode - The underlying mode of the IndexedDb transaction. Can be
   * 'readonly', 'readwrite' or 'readwrite-primary'. Transactions marked
   * 'readwrite-primary' can only be executed by the primary client. In this
   * mode, the transactionOperation will not be run if the primary lease cannot
   * be acquired and the returned promise will be rejected with a
   * FAILED_PRECONDITION error.
   * @param transactionOperation - The operation to run inside a transaction.
   * @returns A promise that is resolved once the transaction completes.
   */
  runTransaction<T>(
    action: string,
    mode: PersistenceTransactionMode,
    transactionOperation: (
      transaction: PersistenceTransaction
    ) => PersistencePromise<T>
  ): Promise<T>;
}

/**
 * PersistencePromise is essentially a re-implementation of Promise except
 * it has a .next() method instead of .then() and .next() and .catch() callbacks
 * are executed synchronously when a PersistencePromise resolves rather than
 * asynchronously (Promise implementations use setImmediate() or similar).
 *
 * This is necessary to interoperate with IndexedDB which will automatically
 * commit transactions if control is returned to the event loop without
 * synchronously initiating another operation on the transaction.
 *
 * NOTE: .then() and .catch() only allow a single consumer, unlike normal
 * Promises.
 */
declare class PersistencePromise<T> {
  private nextCallback;
  private catchCallback;
  private result;
  private error;
  private isDone;
  private callbackAttached;
  constructor(callback: (resolve: Resolver<T>, reject: Rejector) => void);
  catch<R>(
    fn: (error: Error) => R | PersistencePromise<R>
  ): PersistencePromise<R>;
  next<R>(
    nextFn?: FulfilledHandler<T, R>,
    catchFn?: RejectedHandler<R>
  ): PersistencePromise<R>;
  toPromise(): Promise<T>;
  private wrapUserFunction;
  private wrapSuccess;
  private wrapFailure;
  static resolve(): PersistencePromise<void>;
  static resolve<R>(result: R): PersistencePromise<R>;
  static reject<R>(error: Error): PersistencePromise<R>;
  static waitFor(all: {
    forEach: (cb: (el: PersistencePromise<any>) => void) => void;
  }): PersistencePromise<void>;
  /**
   * Given an array of predicate functions that asynchronously evaluate to a
   * boolean, implements a short-circuiting `or` between the results. Predicates
   * will be evaluated until one of them returns `true`, then stop. The final
   * result will be whether any of them returned `true`.
   */
  static or(
    predicates: Array<() => PersistencePromise<boolean>>
  ): PersistencePromise<boolean>;
  /**
   * Given an iterable, call the given function on each element in the
   * collection and wait for all of the resulting concurrent PersistencePromises
   * to resolve.
   */
  static forEach<R, S>(
    collection: {
      forEach: (cb: (r: R, s: S) => void) => void;
    },
    f:
      | ((r: R, s: S) => PersistencePromise<void>)
      | ((r: R) => PersistencePromise<void>)
  ): PersistencePromise<void>;
  static forEach<R>(
    collection: {
      forEach: (cb: (r: R) => void) => void;
    },
    f: (r: R) => PersistencePromise<void>
  ): PersistencePromise<void>;
}

export declare interface PersistenceSettings {
  forceOwnership?: boolean;
}

/**
 * A base class representing a persistence transaction, encapsulating both the
 * transaction's sequence numbers as well as a list of onCommitted listeners.
 *
 * When you call Persistence.runTransaction(), it will create a transaction and
 * pass it to your callback. You then pass it to any method that operates
 * on persistence.
 */
declare abstract class PersistenceTransaction {
  private readonly onCommittedListeners;
  abstract readonly currentSequenceNumber: ListenSequenceNumber;
  addOnCommittedListener(listener: () => void): void;
  raiseOnCommittedEvent(): void;
}

/** The different modes supported by `Persistence.runTransaction()`. */
declare type PersistenceTransactionMode =
  | 'readonly'
  | 'readwrite'
  | 'readwrite-primary';

/**
 * Encodes a precondition for a mutation. This follows the model that the
 * backend accepts with the special case of an explicit "empty" precondition
 * (meaning no precondition).
 */
declare class Precondition {
  readonly updateTime?: SnapshotVersion | undefined;
  readonly exists?: boolean | undefined;
  private constructor();
  /** Creates a new empty Precondition. */
  static none(): Precondition;
  /** Creates a new Precondition with an exists flag. */
  static exists(exists: boolean): Precondition;
  /** Creates a new Precondition based on a version a document exists at. */
  static updateTime(version: SnapshotVersion): Precondition;
  /** Returns whether this Precondition is empty. */
  get isNone(): boolean;
  isEqual(other: Precondition): boolean;
}

/** Undocumented, private additional settings not exposed in our public API. */
declare interface PrivateSettings extends Settings_2 {
  credentials?: CredentialsSettings;
}

declare interface ProviderCredentialsSettings {
  ['type']: 'provider';
  ['client']: CredentialsProvider;
}

/**
 * A `Query` refers to a Query which you can read or listen to. You can also
 * construct refined `Query` objects by adding filters and ordering.
 */
export declare class Query<T = DocumentData> {
  readonly _converter: FirestoreDataConverter_2<T> | null;
  readonly _query: Query_2;
  /** The type of this Firestore reference. */
  readonly type: 'query' | 'collection';
  /**
   * The `FirebaseFirestore` for the Firestore database (useful for performing
   * transactions, etc.).
   */
  readonly firestore: FirebaseFirestore_2;
  /** @hideconstructor protected */
  constructor(
    firestore: FirebaseFirestore_2,
    _converter: FirestoreDataConverter_2<T> | null,
    _query: Query_2
  );
  /**
   * Applies a custom data converter to this query, allowing you to use your own
   * custom model objects with Firestore. When you call {@link getDocs} with
   * the returned query, the provided converter will convert between Firestore
   * data and your custom type `U`.
   *
   * @param converter - Converts objects to and from Firestore.
   * @returns A `Query<U>` that uses the provided converter.
   */
  withConverter<U>(converter: FirestoreDataConverter_2<U>): Query<U>;
}

/**
 * Creates a new immutable instance of `query` that is extended to also include
 * additional query constraints.
 *
 * @param query - The query instance to use as a base for the new constraints.
 * @param queryConstraints - The list of `QueryConstraint`s to apply.
 * @throws if any of the provided query constraints cannot be combined with the
 * existing or new constraints.
 */
export declare function query<T>(
  query: Query<T>,
  ...queryConstraints: QueryConstraint[]
): Query<T>;

/**
 * The Query interface defines all external properties of a query.
 *
 * QueryImpl implements this interface to provide memoization for `queryOrderBy`
 * and `queryToTarget`.
 */
declare interface Query_2 {
  readonly path: ResourcePath;
  readonly collectionGroup: string | null;
  readonly explicitOrderBy: OrderBy[];
  readonly filters: Filter[];
  readonly limit: number | null;
  readonly limitType: LimitType;
  readonly startAt: Bound | null;
  readonly endAt: Bound | null;
}

/**
 * A `QueryConstraint` is used to narrow the set of documents returned by a
 * Firestore query. `QueryConstraint`s are created by invoking {@link where},
 * {@link orderBy}, {@link startAt}, {@link startAfter}, {@link
 * endBefore}, {@link endAt}, {@link limit} or {@link limitToLast} and
 * can then be passed to {@link query} to create a new query instance that
 * also contains this `QueryConstraint`.
 */
export declare abstract class QueryConstraint {
  /** The type of this query constraints */
  abstract readonly type: QueryConstraintType;
  /**
   * Takes the provided `Query` and returns a copy of the `Query` with this
   * `QueryConstraint` applied.
   */
  abstract _apply<T>(query: Query<T>): Query<T>;
}

/** Describes the different query constraints available in this SDK. */
export declare type QueryConstraintType =
  | 'where'
  | 'orderBy'
  | 'limit'
  | 'limitToLast'
  | 'startAt'
  | 'startAfter'
  | 'endAt'
  | 'endBefore';

/**
 * A `QueryDocumentSnapshot` contains data read from a document in your
 * Firestore database as part of a query. The document is guaranteed to exist
 * and its data can be extracted with `.data()` or `.get(<field>)` to get a
 * specific field.
 *
 * A `QueryDocumentSnapshot` offers the same API surface as a
 * `DocumentSnapshot`. Since query results contain only existing documents, the
 * `exists` property will always be true and `data()` will never return
 * 'undefined'.
 */
export declare class QueryDocumentSnapshot<
  T = DocumentData
> extends DocumentSnapshot<T> {
  /**
   * Retrieves all fields in the document as an `Object`.
   *
   * By default, `FieldValue.serverTimestamp()` values that have not yet been
   * set to their final value will be returned as `null`. You can override
   * this by passing an options object.
   *
   * @override
   * @param options - An options object to configure how data is retrieved from
   * the snapshot (for example the desired behavior for server timestamps that
   * have not yet been set to their final value).
   * @returns An `Object` containing all fields in the document.
   */
  data(options?: SnapshotOptions): T;
}

/**
 * A `QueryDocumentSnapshot` contains data read from a document in your
 * Firestore database as part of a query. The document is guaranteed to exist
 * and its data can be extracted with `.data()` or `.get(<field>)` to get a
 * specific field.
 *
 * A `QueryDocumentSnapshot` offers the same API surface as a
 * `DocumentSnapshot`. Since query results contain only existing documents, the
 * `exists` property will always be true and `data()` will never return
 * 'undefined'.
 */
declare class QueryDocumentSnapshot_2<
  T = DocumentData
> extends DocumentSnapshot_2<T> {
  /**
   * Retrieves all fields in the document as an `Object`.
   *
   * @override
   * @returns An `Object` containing all fields in the document.
   */
  data(): T;
}

/**
 * Returns true if the provided queries point to the same collection and apply
 * the same constraints.
 *
 * @param left - A `Query` to compare.
 * @param right - A `Query` to compare.
 * @returns true if the references point to the same location in the same
 * Firestore database.
 */
export declare function queryEqual<T>(left: Query<T>, right: Query<T>): boolean;

/**
 * A `QuerySnapshot` contains zero or more `DocumentSnapshot` objects
 * representing the results of a query. The documents can be accessed as an
 * array via the `docs` property or enumerated using the `forEach` method. The
 * number of documents can be determined via the `empty` and `size`
 * properties.
 */
export declare class QuerySnapshot<T = DocumentData> {
  readonly _firestore: FirebaseFirestore;
  readonly _userDataWriter: AbstractUserDataWriter;
  readonly _snapshot: ViewSnapshot;
  /**
   * Metadata about this snapshot, concerning its source and if it has local
   * modifications.
   */
  readonly metadata: SnapshotMetadata;
  /**
   * The query on which you called `get` or `onSnapshot` in order to get this
   * `QuerySnapshot`.
   */
  readonly query: Query<T>;
  private _cachedChanges?;
  private _cachedChangesIncludeMetadataChanges?;
  /** @hideconstructor */
  constructor(
    _firestore: FirebaseFirestore,
    _userDataWriter: AbstractUserDataWriter,
    query: Query<T>,
    _snapshot: ViewSnapshot
  );
  /** An array of all the documents in the `QuerySnapshot`. */
  get docs(): Array<QueryDocumentSnapshot<T>>;
  /** The number of documents in the `QuerySnapshot`. */
  get size(): number;
  /** True if there are no documents in the `QuerySnapshot`. */
  get empty(): boolean;
  /**
   * Enumerates all of the documents in the `QuerySnapshot`.
   *
   * @param callback - A callback to be called with a `QueryDocumentSnapshot` for
   * each document in the snapshot.
   * @param thisArg - The `this` binding for the callback.
   */
  forEach(
    callback: (result: QueryDocumentSnapshot<T>) => void,
    thisArg?: unknown
  ): void;
  /**
   * Returns an array of the documents changes since the last snapshot. If this
   * is the first snapshot, all documents will be in the list as 'added'
   * changes.
   *
   * @param options - `SnapshotListenOptions` that control whether metadata-only
   * changes (i.e. only `DocumentSnapshot.metadata` changed) should trigger
   * snapshot events.
   */
  docChanges(options?: SnapshotListenOptions): Array<DocumentChange<T>>;
}

/** The different states of a watch target. */
declare type QueryTargetState = 'not-current' | 'current' | 'rejected';

/**
 * Returns true if the provided references are equal.
 *
 * @param left - A reference to compare.
 * @param right - A reference to compare.
 * @returns true if the references point to the same location in the same
 * Firestore database.
 */
export declare function refEqual<T>(
  left: DocumentReference<T> | CollectionReference<T>,
  right: DocumentReference<T> | CollectionReference<T>
): boolean;

/**
 * A ReferenceDelegate instance handles all of the hooks into the document-reference lifecycle. This
 * includes being added to a target, being removed from a target, being subject to mutation, and
 * being mutated by the user.
 *
 * Different implementations may do different things with each of these events. Not every
 * implementation needs to do something with every lifecycle hook.
 *
 * PORTING NOTE: since sequence numbers are attached to transactions in this
 * client, the ReferenceDelegate does not need to deal in transactional
 * semantics (onTransactionStarted/Committed()), nor does it need to track and
 * generate sequence numbers (getCurrentSequenceNumber()).
 */
declare interface ReferenceDelegate {
  /** Notify the delegate that the given document was added to a target. */
  addReference(
    txn: PersistenceTransaction,
    targetId: TargetId,
    doc: DocumentKey
  ): PersistencePromise<void>;
  /** Notify the delegate that the given document was removed from a target. */
  removeReference(
    txn: PersistenceTransaction,
    targetId: TargetId,
    doc: DocumentKey
  ): PersistencePromise<void>;
  /**
   * Notify the delegate that a target was removed. The delegate may, but is not obligated to,
   * actually delete the target and associated data.
   */
  removeTarget(
    txn: PersistenceTransaction,
    targetData: TargetData
  ): PersistencePromise<void>;
  /**
   * Notify the delegate that a document may no longer be part of any views or
   * have any mutations associated.
   */
  markPotentiallyOrphaned(
    txn: PersistenceTransaction,
    doc: DocumentKey
  ): PersistencePromise<void>;
  /** Notify the delegate that a limbo document was updated. */
  updateLimboDocument(
    txn: PersistenceTransaction,
    doc: DocumentKey
  ): PersistencePromise<void>;
}

declare type RejectedHandler<R> =
  | ((reason: Error) => R | PersistencePromise<R>)
  | null;

declare type Rejector = (error: Error) => void;

/**
 * Represents cached documents received from the remote backend.
 *
 * The cache is keyed by DocumentKey and entries in the cache are MaybeDocument
 * instances, meaning we can cache both Document instances (an actual document
 * with data) as well as NoDocument instances (indicating that the document is
 * known to not exist).
 */
declare interface RemoteDocumentCache {
  /**
   * Looks up an entry in the cache.
   *
   * @param documentKey - The key of the entry to look up.*
   * @returns The cached Document or NoDocument entry, or null if we have
   * nothing cached.
   */
  getEntry(
    transaction: PersistenceTransaction,
    documentKey: DocumentKey
  ): PersistencePromise<MaybeDocument | null>;
  /**
   * Looks up a set of entries in the cache.
   *
   * @param documentKeys - The keys of the entries to look up.
   * @returns The cached Document or NoDocument entries indexed by key. If an
   * entry is not cached, the corresponding key will be mapped to a null value.
   */
  getEntries(
    transaction: PersistenceTransaction,
    documentKeys: DocumentKeySet
  ): PersistencePromise<NullableMaybeDocumentMap>;
  /**
   * Executes a query against the cached Document entries.
   *
   * Implementations may return extra documents if convenient. The results
   * should be re-filtered by the consumer before presenting them to the user.
   *
   * Cached NoDocument entries have no bearing on query results.
   *
   * @param query - The query to match documents against.
   * @param sinceReadTime - If not set to SnapshotVersion.min(), return only
   *     documents that have been read since this snapshot version (exclusive).
   * @returns The set of matching documents.
   */
  getDocumentsMatchingQuery(
    transaction: PersistenceTransaction,
    query: Query_2,
    sinceReadTime: SnapshotVersion
  ): PersistencePromise<DocumentMap>;
  /**
   * Provides access to add or update the contents of the cache. The buffer
   * handles proper size accounting for the change.
   *
   * Multi-Tab Note: This should only be called by the primary client.
   *
   * @param options - Specify `trackRemovals` to create sentinel entries for
   * removed documents, which allows removals to be tracked by
   * `getNewDocumentChanges()`.
   */
  newChangeBuffer(options?: {
    trackRemovals: boolean;
  }): RemoteDocumentChangeBuffer;
  /**
   * Get an estimate of the size of the document cache. Note that for eager
   * garbage collection, we don't track sizes so this will return 0.
   */
  getSize(transaction: PersistenceTransaction): PersistencePromise<number>;
}

/**
 * Represents a document change to be applied to remote document cache.
 */
declare interface RemoteDocumentChange {
  readonly maybeDocument: MaybeDocument | null;
  readonly readTime: SnapshotVersion | null;
}

/**
 * An in-memory buffer of entries to be written to a RemoteDocumentCache.
 * It can be used to batch up a set of changes to be written to the cache, but
 * additionally supports reading entries back with the `getEntry()` method,
 * falling back to the underlying RemoteDocumentCache if no entry is
 * buffered.
 *
 * Entries added to the cache *must* be read first. This is to facilitate
 * calculating the size delta of the pending changes.
 *
 * PORTING NOTE: This class was implemented then removed from other platforms.
 * If byte-counting ends up being needed on the other platforms, consider
 * porting this class as part of that implementation work.
 */
declare abstract class RemoteDocumentChangeBuffer {
  protected changes: ObjectMap<DocumentKey, RemoteDocumentChange>;
  private changesApplied;
  protected abstract getFromCache(
    transaction: PersistenceTransaction,
    documentKey: DocumentKey
  ): PersistencePromise<MaybeDocument | null>;
  protected abstract getAllFromCache(
    transaction: PersistenceTransaction,
    documentKeys: DocumentKeySet
  ): PersistencePromise<NullableMaybeDocumentMap>;
  protected abstract applyChanges(
    transaction: PersistenceTransaction
  ): PersistencePromise<void>;
  protected getReadTime(key: DocumentKey): SnapshotVersion;
  /**
   * Buffers a `RemoteDocumentCache.addEntry()` call.
   *
   * You can only modify documents that have already been retrieved via
   * `getEntry()/getEntries()` (enforced via IndexedDbs `apply()`).
   */
  addEntry(maybeDocument: MaybeDocument, readTime: SnapshotVersion): void;
  /**
   * Buffers a `RemoteDocumentCache.removeEntry()` call.
   *
   * You can only remove documents that have already been retrieved via
   * `getEntry()/getEntries()` (enforced via IndexedDbs `apply()`).
   */
  removeEntry(key: DocumentKey, readTime?: SnapshotVersion | null): void;
  /**
   * Looks up an entry in the cache. The buffered changes will first be checked,
   * and if no buffered change applies, this will forward to
   * `RemoteDocumentCache.getEntry()`.
   *
   * @param transaction - The transaction in which to perform any persistence
   *     operations.
   * @param documentKey - The key of the entry to look up.
   * @returns The cached Document or NoDocument entry, or null if we have
   *     nothing cached.
   */
  getEntry(
    transaction: PersistenceTransaction,
    documentKey: DocumentKey
  ): PersistencePromise<MaybeDocument | null>;
  /**
   * Looks up several entries in the cache, forwarding to
   * `RemoteDocumentCache.getEntry()`.
   *
   * @param transaction - The transaction in which to perform any persistence
   *     operations.
   * @param documentKeys - The keys of the entries to look up.
   * @returns A map of cached `Document`s or `NoDocument`s, indexed by key. If
   *     an entry cannot be found, the corresponding key will be mapped to a
   *     null value.
   */
  getEntries(
    transaction: PersistenceTransaction,
    documentKeys: DocumentKeySet
  ): PersistencePromise<NullableMaybeDocumentMap>;
  /**
   * Applies buffered changes to the underlying RemoteDocumentCache, using
   * the provided transaction.
   */
  apply(transaction: PersistenceTransaction): PersistencePromise<void>;
  /** Helper to assert this.changes is not null  */
  protected assertNotApplied(): void;
}

/**
 * An event from the RemoteStore. It is split into targetChanges (changes to the
 * state or the set of documents in our watched targets) and documentUpdates
 * (changes to the actual documents).
 */
declare class RemoteEvent {
  /**
   * The snapshot version this event brings us up to, or MIN if not set.
   */
  readonly snapshotVersion: SnapshotVersion;
  /**
   * A map from target to changes to the target. See TargetChange.
   */
  readonly targetChanges: Map<TargetId, TargetChange>;
  /**
   * A set of targets that is known to be inconsistent. Listens for these
   * targets should be re-established without resume tokens.
   */
  readonly targetMismatches: SortedSet<TargetId>;
  /**
   * A set of which documents have changed or been deleted, along with the
   * doc's new values (if not deleted).
   */
  readonly documentUpdates: MaybeDocumentMap;
  /**
   * A set of which document updates are due only to limbo resolution targets.
   */
  readonly resolvedLimboDocuments: DocumentKeySet;
  constructor(
    /**
     * The snapshot version this event brings us up to, or MIN if not set.
     */
    snapshotVersion: SnapshotVersion,
    /**
     * A map from target to changes to the target. See TargetChange.
     */
    targetChanges: Map<TargetId, TargetChange>,
    /**
     * A set of targets that is known to be inconsistent. Listens for these
     * targets should be re-established without resume tokens.
     */
    targetMismatches: SortedSet<TargetId>,
    /**
     * A set of which documents have changed or been deleted, along with the
     * doc's new values (if not deleted).
     */
    documentUpdates: MaybeDocumentMap,
    /**
     * A set of which document updates are due only to limbo resolution targets.
     */
    resolvedLimboDocuments: DocumentKeySet
  );
  /**
   * HACK: Views require RemoteEvents in order to determine whether the view is
   * CURRENT, but secondary tabs don't receive remote events. So this method is
   * used to create a synthesized RemoteEvent that can be used to apply a
   * CURRENT status change to a View, for queries executed in a different tab.
   */
  static createSynthesizedRemoteEventForCurrentChange(
    targetId: TargetId,
    current: boolean
  ): RemoteEvent;
}

/**
 * RemoteStore - An interface to remotely stored data, basically providing a
 * wrapper around the Datastore that is more reliable for the rest of the
 * system.
 *
 * RemoteStore is responsible for maintaining the connection to the server.
 * - maintaining a list of active listens.
 * - reconnecting when the connection is dropped.
 * - resuming all the active listens on reconnect.
 *
 * RemoteStore handles all incoming events from the Datastore.
 * - listening to the watch stream and repackaging the events as RemoteEvents
 * - notifying SyncEngine of any changes to the active listens.
 *
 * RemoteStore takes writes from other components and handles them reliably.
 * - pulling pending mutations from LocalStore and sending them to Datastore.
 * - retrying mutations that failed because of network problems.
 * - acking mutations to the SyncEngine once they are accepted or rejected.
 */
declare interface RemoteStore {
  /**
   * SyncEngine to notify of watch and write events. This must be set
   * immediately after construction.
   */
  remoteSyncer: RemoteSyncer;
}

/**
 * An interface that describes the actions the RemoteStore needs to perform on
 * a cooperating synchronization engine.
 */
declare interface RemoteSyncer {
  /**
   * Applies one remote event to the sync engine, notifying any views of the
   * changes, and releasing any pending mutation batches that would become
   * visible because of the snapshot version the remote event contains.
   */
  applyRemoteEvent?(remoteEvent: RemoteEvent): Promise<void>;
  /**
   * Rejects the listen for the given targetID. This can be triggered by the
   * backend for any active target.
   *
   * @param targetId - The targetID corresponds to one previously initiated by
   * the user as part of TargetData passed to listen() on RemoteStore.
   * @param error - A description of the condition that has forced the rejection.
   * Nearly always this will be an indication that the user is no longer
   * authorized to see the data matching the target.
   */
  rejectListen?(targetId: TargetId, error: FirestoreError): Promise<void>;
  /**
   * Applies the result of a successful write of a mutation batch to the sync
   * engine, emitting snapshots in any views that the mutation applies to, and
   * removing the batch from the mutation queue.
   */
  applySuccessfulWrite?(result: MutationBatchResult): Promise<void>;
  /**
   * Rejects the batch, removing the batch from the mutation queue, recomputing
   * the local view of any documents affected by the batch and then, emitting
   * snapshots with the reverted value.
   */
  rejectFailedWrite?(batchId: BatchId, error: FirestoreError): Promise<void>;
  /**
   * Returns the set of remote document keys for the given target ID. This list
   * includes the documents that were assigned to the target when we received
   * the last snapshot.
   */
  getRemoteKeysForTarget?(targetId: TargetId): DocumentKeySet;
  /**
   * Updates all local state to match the pending mutations for the given user.
   * May be called repeatedly for the same user.
   */
  handleCredentialChange?(user: User): Promise<void>;
}

declare type Resolver<T> = (value?: T) => void;

/**
 * A slash-separated path for navigating resources (documents and collections)
 * within Firestore.
 */
declare class ResourcePath extends BasePath<ResourcePath> {
  protected construct(
    segments: string[],
    offset?: number,
    length?: number
  ): ResourcePath;
  canonicalString(): string;
  toString(): string;
  /**
   * Creates a resource path from the given slash-delimited string. If multiple
   * arguments are provided, all components are combined. Leading and trailing
   * slashes from all components are ignored.
   */
  static fromString(...pathComponents: string[]): ResourcePath;
  static emptyPath(): ResourcePath;
}

/**
 * Executes the given `updateFunction` and then attempts to commit the changes
 * applied within the transaction. If any document read within the transaction
 * has changed, Cloud Firestore retries the `updateFunction`. If it fails to
 * commit after 5 attempts, the transaction fails.
 *
 * The maximum number of writes allowed in a single transaction is 500.
 *
 * @param firestore - A reference to the Firestore database to run this
 * transaction against.
 * @param updateFunction - The function to execute within the transaction
 * context.
 * @returns If the transaction completed successfully or was explicitly aborted
 * (the `updateFunction` returned a failed promise), the promise returned by the
 * `updateFunction `is returned here. Otherwise, if the transaction failed, a
 * rejected promise with the corresponding failure error is returned.
 */
export declare function runTransaction<T>(
  firestore: FirebaseFirestore,
  updateFunction: (transaction: Transaction) => Promise<T>
): Promise<T>;

/**
 * Returns a sentinel used with {@link setDoc} or {@link updateDoc} to
 * include a server-generated timestamp in the written data.
 */
export declare function serverTimestamp(): FieldValue;

declare type ServerTimestampBehavior = 'estimate' | 'previous' | 'none';

/**
 * Writes to the document referred to by this `DocumentReference`. If the
 * document does not yet exist, it will be created.
 *
 * @param reference - A reference to the document to write.
 * @param data - A map of the fields and values for the document.
 * @returns A Promise resolved once the data has been successfully written
 * to the backend (note that it won't resolve while you're offline).
 */
export declare function setDoc<T>(
  reference: DocumentReference<T>,
  data: T
): Promise<void>;

/**
 * Writes to the document referred to by the specified `DocumentReference`. If
 * the document does not yet exist, it will be created. If you provide `merge`
 * or `mergeFields`, the provided data can be merged into an existing document.
 *
 * @param reference - A reference to the document to write.
 * @param data - A map of the fields and values for the document.
 * @param options - An object to configure the set behavior.
 * @returns A Promise resolved once the data has been successfully written
 * to the backend (note that it won't resolve while you're offline).
 */
export declare function setDoc<T>(
  reference: DocumentReference<T>,
  data: Partial<T>,
  options: SetOptions
): Promise<void>;

/**
 * Sets the verbosity of Cloud Firestore logs (debug, error, or silent).
 *
 * @param logLevel - The verbosity you set for activity and error logging. Can
 *   be any of the following values:
 *
 *   <ul>
 *     <li>`debug` for the most verbose logging level, primarily for
 *     debugging.</li>
 *     <li>`error` to log errors only.</li>
 *     <li><code>`silent` to turn off logging.</li>
 *   </ul>
 */
export declare function setLogLevel(logLevel: LogLevel): void;

/**
 * An options object that configures the behavior of {@link setDoc}, {@link
 * WriteBatch#set} and {@link Transaction#set} calls. These calls can be
 * configured to perform granular merges instead of overwriting the target
 * documents in their entirety by providing a `SetOptions` with `merge: true`.
 *
 * @param merge - Changes the behavior of a `setDoc()` call to only replace the
 * values specified in its data argument. Fields omitted from the `setDoc()`
 * call remain untouched.
 * @param mergeFields - Changes the behavior of `setDoc()` calls to only replace
 * the specified field paths. Any field path that is not specified is ignored
 * and remains untouched.
 */
export declare type SetOptions =
  | {
      readonly merge?: boolean;
    }
  | {
      readonly mergeFields?: Array<string | FieldPath>;
    };

export declare interface Settings extends Settings_2 {
  cacheSizeBytes?: number;
}

declare interface Settings_2 {
  host?: string;
  ssl?: boolean;
  ignoreUndefinedProperties?: boolean;
  cacheSizeBytes?: number;
  experimentalForceLongPolling?: boolean;
  experimentalAutoDetectLongPolling?: boolean;
}

/**
 * A `SharedClientState` keeps track of the global state of the mutations
 * and query targets for all active clients with the same persistence key (i.e.
 * project ID and FirebaseApp name). It relays local changes to other clients
 * and updates its local state as new state is observed.
 *
 * `SharedClientState` is primarily used for synchronization in Multi-Tab
 * environments. Each tab is responsible for registering its active query
 * targets and mutations. `SharedClientState` will then notify the listener
 * assigned to `.syncEngine` for updates to mutations and queries that
 * originated in other clients.
 *
 * To receive notifications, `.syncEngine` and `.onlineStateHandler` has to be
 * assigned before calling `start()`.
 */
declare interface SharedClientState {
  onlineStateHandler: ((onlineState: OnlineState) => void) | null;
  sequenceNumberHandler:
    | ((sequenceNumber: ListenSequenceNumber) => void)
    | null;
  /** Registers the Mutation Batch ID of a newly pending mutation. */
  addPendingMutation(batchId: BatchId): void;
  /**
   * Records that a pending mutation has been acknowledged or rejected.
   * Called by the primary client to notify secondary clients of mutation
   * results as they come back from the backend.
   */
  updateMutationState(
    batchId: BatchId,
    state: 'acknowledged' | 'rejected',
    error?: FirestoreError
  ): void;
  /**
   * Associates a new Query Target ID with the local Firestore client. Returns
   * the new query state for the query (which can be 'current' if the query is
   * already associated with another tab).
   *
   * If the target id is already associated with local client, the method simply
   * returns its `QueryTargetState`.
   */
  addLocalQueryTarget(targetId: TargetId): QueryTargetState;
  /** Removes the Query Target ID association from the local client. */
  removeLocalQueryTarget(targetId: TargetId): void;
  /** Checks whether the target is associated with the local client. */
  isLocalQueryTarget(targetId: TargetId): boolean;
  /**
   * Processes an update to a query target.
   *
   * Called by the primary client to notify secondary clients of document
   * changes or state transitions that affect the provided query target.
   */
  updateQueryState(
    targetId: TargetId,
    state: QueryTargetState,
    error?: FirestoreError
  ): void;
  /**
   * Removes the target's metadata entry.
   *
   * Called by the primary client when all clients stopped listening to a query
   * target.
   */
  clearQueryState(targetId: TargetId): void;
  /**
   * Gets the active Query Targets IDs for all active clients.
   *
   * The implementation for this may require O(n) runtime, where 'n' is the size
   * of the result set.
   */
  getAllActiveQueryTargets(): SortedSet<TargetId>;
  /**
   * Checks whether the provided target ID is currently being listened to by
   * any of the active clients.
   *
   * The implementation may require O(n*log m) runtime, where 'n' is the number
   * of clients and 'm' the number of targets.
   */
  isActiveQueryTarget(targetId: TargetId): boolean;
  /**
   * Starts the SharedClientState, reads existing client data and registers
   * listeners for updates to new and existing clients.
   */
  start(): Promise<void>;
  /** Shuts down the `SharedClientState` and its listeners. */
  shutdown(): void;
  /**
   * Changes the active user and removes all existing user-specific data. The
   * user change does not call back into SyncEngine (for example, no mutations
   * will be marked as removed).
   */
  handleUserChange(
    user: User,
    removedBatchIds: BatchId[],
    addedBatchIds: BatchId[]
  ): void;
  /** Changes the shared online state of all clients. */
  setOnlineState(onlineState: OnlineState): void;
  writeSequenceNumber(sequenceNumber: ListenSequenceNumber): void;
  /**
   * Notifies other clients when remote documents have changed due to loading
   * a bundle.
   */
  notifyBundleLoaded(): void;
}

/**
 * Returns true if the provided snapshots are equal.
 *
 * @param left - A snapshot to compare.
 * @param right - A snapshot to compare.
 * @returns true if the snapshots are equal.
 */
export declare function snapshotEqual<T>(
  left: DocumentSnapshot<T> | QuerySnapshot<T>,
  right: DocumentSnapshot<T> | QuerySnapshot<T>
): boolean;

/**
 * An options object that can be passed to {@link onSnapshot} and {@link
 * QuerySnapshot#docChanges} to control which types of changes to include in the
 * result set.
 */
export declare interface SnapshotListenOptions {
  /**
   * Include a change even if only the metadata of the query or of a document
   * changed. Default is false.
   */
  readonly includeMetadataChanges?: boolean;
}

/**
 * Metadata about a snapshot, describing the state of the snapshot.
 */
export declare class SnapshotMetadata {
  /**
   * True if the snapshot contains the result of local writes (for example
   * `set()` or `update()` calls) that have not yet been committed to the
   * backend. If your listener has opted into metadata updates (via
   * `SnapshotListenOptions`) you will receive another snapshot with
   * `hasPendingWrites` equal to false once the writes have been committed to
   * the backend.
   */
  readonly hasPendingWrites: boolean;
  /**
   * True if the snapshot was created from cached data rather than guaranteed
   * up-to-date server data. If your listener has opted into metadata updates
   * (via `SnapshotListenOptions`) you will receive another snapshot with
   * `fromCache` set to false once the client has received up-to-date data from
   * the backend.
   */
  readonly fromCache: boolean;
  /** @hideconstructor */
  constructor(hasPendingWrites: boolean, fromCache: boolean);
  /**
   * Returns true if this `SnapshotMetadata` is equal to the provided one.
   *
   * @param other - The `SnapshotMetadata` to compare against.
   * @returns true if this `SnapshotMetadata` is equal to the provided one.
   */
  isEqual(other: SnapshotMetadata): boolean;
}

/**
 * Options that configure how data is retrieved from a `DocumentSnapshot` (for
 * example the desired behavior for server timestamps that have not yet been set
 * to their final value).
 */
export declare interface SnapshotOptions {
  /**
   * If set, controls the return value for server timestamps that have not yet
   * been set to their final value.
   *
   * By specifying 'estimate', pending server timestamps return an estimate
   * based on the local clock. This estimate will differ from the final value
   * and cause these values to change once the server result becomes available.
   *
   * By specifying 'previous', pending timestamps will be ignored and return
   * their previous value instead.
   *
   * If omitted or set to 'none', `null` will be returned by default until the
   * server value becomes available.
   */
  readonly serverTimestamps?: 'estimate' | 'previous' | 'none';
}

/**
 * A version of a document in Firestore. This corresponds to the version
 * timestamp, such as update_time or read_time.
 */
declare class SnapshotVersion {
  private timestamp;
  static fromTimestamp(value: Timestamp): SnapshotVersion;
  static min(): SnapshotVersion;
  private constructor();
  compareTo(other: SnapshotVersion): number;
  isEqual(other: SnapshotVersion): boolean;
  /** Returns a number representation of the version for use in spec tests. */
  toMicroseconds(): number;
  toString(): string;
  toTimestamp(): Timestamp;
}

declare class SortedMap<K, V> {
  comparator: Comparator<K>;
  root: LLRBNode<K, V> | LLRBEmptyNode<K, V>;
  constructor(
    comparator: Comparator<K>,
    root?: LLRBNode<K, V> | LLRBEmptyNode<K, V>
  );
  insert(key: K, value: V): SortedMap<K, V>;
  remove(key: K): SortedMap<K, V>;
  get(key: K): V | null;
  indexOf(key: K): number;
  isEmpty(): boolean;
  get size(): number;
  minKey(): K | null;
  maxKey(): K | null;
  inorderTraversal<T>(action: (k: K, v: V) => T): T;
  forEach(fn: (k: K, v: V) => void): void;
  toString(): string;
  reverseTraversal<T>(action: (k: K, v: V) => T): T;
  getIterator(): SortedMapIterator<K, V>;
  getIteratorFrom(key: K): SortedMapIterator<K, V>;
  getReverseIterator(): SortedMapIterator<K, V>;
  getReverseIteratorFrom(key: K): SortedMapIterator<K, V>;
}

declare class SortedMapIterator<K, V> {
  private isReverse;
  private nodeStack;
  constructor(
    node: LLRBNode<K, V> | LLRBEmptyNode<K, V>,
    startKey: K | null,
    comparator: Comparator<K>,
    isReverse: boolean
  );
  getNext(): Entry<K, V>;
  hasNext(): boolean;
  peek(): Entry<K, V> | null;
}

/**
 * SortedSet is an immutable (copy-on-write) collection that holds elements
 * in order specified by the provided comparator.
 *
 * NOTE: if provided comparator returns 0 for two elements, we consider them to
 * be equal!
 */
declare class SortedSet<T> {
  private comparator;
  private data;
  constructor(comparator: (left: T, right: T) => number);
  has(elem: T): boolean;
  first(): T | null;
  last(): T | null;
  get size(): number;
  indexOf(elem: T): number;
  /** Iterates elements in order defined by "comparator" */
  forEach(cb: (elem: T) => void): void;
  /** Iterates over `elem`s such that: range[0] &lt;= elem &lt; range[1]. */
  forEachInRange(range: [T, T], cb: (elem: T) => void): void;
  /**
   * Iterates over `elem`s such that: start &lt;= elem until false is returned.
   */
  forEachWhile(cb: (elem: T) => boolean, start?: T): void;
  /** Finds the least element greater than or equal to `elem`. */
  firstAfterOrEqual(elem: T): T | null;
  getIterator(): SortedSetIterator<T>;
  getIteratorFrom(key: T): SortedSetIterator<T>;
  /** Inserts or updates an element */
  add(elem: T): SortedSet<T>;
  /** Deletes an element */
  delete(elem: T): SortedSet<T>;
  isEmpty(): boolean;
  unionWith(other: SortedSet<T>): SortedSet<T>;
  isEqual(other: SortedSet<T>): boolean;
  toArray(): T[];
  toString(): string;
  private copy;
}

declare class SortedSetIterator<T> {
  private iter;
  constructor(iter: SortedMapIterator<T, boolean>);
  getNext(): T;
  hasNext(): boolean;
}

/**
 * Creates a `QueryConstraint` that modifies the result set to start after the
 * provided document (exclusive). The starting position is relative to the order
 * of the query. The document must contain all of the fields provided in the
 * orderBy of the query.
 *
 * @param snapshot - The snapshot of the document to start after.
 * @returns A `QueryConstraint` to pass to `query()`
 */
export declare function startAfter(
  snapshot: DocumentSnapshot_2<unknown>
): QueryConstraint;

/**
 * Creates a `QueryConstraint` that modifies the result set to start after the
 * provided fields relative to the order of the query. The order of the field
 * values must match the order of the order by clauses of the query.
 *
 * @param fieldValues - The field values to start this query after, in order
 * of the query's order by.
 * @returns A `QueryConstraint` to pass to `query()`
 */
export declare function startAfter(...fieldValues: unknown[]): QueryConstraint;

/**
 * Creates a `QueryConstraint` that modifies the result set to start at the
 * provided document (inclusive). The starting position is relative to the order
 * of the query. The document must contain all of the fields provided in the
 * `orderBy` of this query.
 *
 * @param snapshot - The snapshot of the document to start at.
 * @returns A `QueryConstraint` to pass to `query()`.
 */
export declare function startAt(
  snapshot: DocumentSnapshot_2<unknown>
): QueryConstraint;

/**
 * Creates a `QueryConstraint` that modifies the result set to start at the
 * provided fields relative to the order of the query. The order of the field
 * values must match the order of the order by clauses of the query.
 *
 * @param fieldValues - The field values to start this query at, in order
 * of the query's order by.
 * @returns A `QueryConstraint` to pass to `query()`.
 */
export declare function startAt(...fieldValues: unknown[]): QueryConstraint;

declare type StructuredQuery = firestoreV1ApiClientInterfaces.StructuredQuery;

/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
/**
 * SyncEngine is the central controller in the client SDK architecture. It is
 * the glue code between the EventManager, LocalStore, and RemoteStore. Some of
 * SyncEngine's responsibilities include:
 * 1. Coordinating client requests and remote events between the EventManager
 *    and the local and remote data stores.
 * 2. Managing a View object for each query, providing the unified view between
 *    the local and remote data stores.
 * 3. Notifying the RemoteStore when the LocalStore has new mutations in its
 *    queue that need sending to the backend.
 *
 * The SyncEngine’s methods should only ever be called by methods running in the
 * global async queue.
 *
 * PORTING NOTE: On Web, SyncEngine does not have an explicit subscribe()
 * function. Instead, it directly depends on EventManager's tree-shakeable API
 * (via `ensureWatchStream()`).
 */
declare interface SyncEngine {
  isPrimaryClient: boolean;
}

/**
 * A Target represents the WatchTarget representation of a Query, which is used
 * by the LocalStore and the RemoteStore to keep track of and to execute
 * backend queries. While a Query can represent multiple Targets, each Targets
 * maps to a single WatchTarget in RemoteStore and a single TargetData entry
 * in persistence.
 */
declare interface Target {
  readonly path: ResourcePath;
  readonly collectionGroup: string | null;
  readonly orderBy: OrderBy[];
  readonly filters: Filter[];
  readonly limit: number | null;
  readonly startAt: Bound | null;
  readonly endAt: Bound | null;
}

/**
 * Represents cached targets received from the remote backend.
 *
 * The cache is keyed by `Target` and entries in the cache are `TargetData`
 * instances.
 */
declare interface TargetCache {
  /**
   * A global snapshot version representing the last consistent snapshot we
   * received from the backend. This is monotonically increasing and any
   * snapshots received from the backend prior to this version (e.g. for targets
   * resumed with a resume_token) should be suppressed (buffered) until the
   * backend has caught up to this snapshot version again. This prevents our
   * cache from ever going backwards in time.
   *
   * This is updated whenever our we get a TargetChange with a read_time and
   * empty target_ids.
   */
  getLastRemoteSnapshotVersion(
    transaction: PersistenceTransaction
  ): PersistencePromise<SnapshotVersion>;
  /**
   * @returns The highest sequence number observed, including any that might be
   *         persisted on-disk.
   */
  getHighestSequenceNumber(
    transaction: PersistenceTransaction
  ): PersistencePromise<ListenSequenceNumber>;
  /**
   * Call provided function with each `TargetData` that we have cached.
   */
  forEachTarget(
    txn: PersistenceTransaction,
    f: (q: TargetData) => void
  ): PersistencePromise<void>;
  /**
   * Set the highest listen sequence number and optionally updates the
   * snapshot version of the last consistent snapshot received from the backend
   * (see getLastRemoteSnapshotVersion() for more details).
   *
   * @param highestListenSequenceNumber - The new maximum listen sequence number.
   * @param lastRemoteSnapshotVersion - The new snapshot version. Optional.
   */
  setTargetsMetadata(
    transaction: PersistenceTransaction,
    highestListenSequenceNumber: number,
    lastRemoteSnapshotVersion?: SnapshotVersion
  ): PersistencePromise<void>;
  /**
   * Adds an entry in the cache.
   *
   * The cache key is extracted from `targetData.target`. The key must not already
   * exist in the cache.
   *
   * @param targetData - A TargetData instance to put in the cache.
   */
  addTargetData(
    transaction: PersistenceTransaction,
    targetData: TargetData
  ): PersistencePromise<void>;
  /**
   * Updates an entry in the cache.
   *
   * The cache key is extracted from `targetData.target`. The entry must already
   * exist in the cache, and it will be replaced.
   * @param targetData - The TargetData to be replaced into the cache.
   */
  updateTargetData(
    transaction: PersistenceTransaction,
    targetData: TargetData
  ): PersistencePromise<void>;
  /**
   * Removes the cached entry for the given target data. It is an error to remove
   * a target data that does not exist.
   *
   * Multi-Tab Note: This operation should only be called by the primary client.
   */
  removeTargetData(
    transaction: PersistenceTransaction,
    targetData: TargetData
  ): PersistencePromise<void>;
  /**
   * The number of targets currently in the cache.
   */
  getTargetCount(
    transaction: PersistenceTransaction
  ): PersistencePromise<number>;
  /**
   * Looks up a TargetData entry by target.
   *
   * @param target - The query target corresponding to the entry to look up.
   * @returns The cached TargetData entry, or null if the cache has no entry for
   * the target.
   */
  getTargetData(
    transaction: PersistenceTransaction,
    target: Target
  ): PersistencePromise<TargetData | null>;
  /**
   * Adds the given document keys to cached query results of the given target
   * ID.
   *
   * Multi-Tab Note: This operation should only be called by the primary client.
   */
  addMatchingKeys(
    transaction: PersistenceTransaction,
    keys: DocumentKeySet,
    targetId: TargetId
  ): PersistencePromise<void>;
  /**
   * Removes the given document keys from the cached query results of the
   * given target ID.
   *
   * Multi-Tab Note: This operation should only be called by the primary client.
   */
  removeMatchingKeys(
    transaction: PersistenceTransaction,
    keys: DocumentKeySet,
    targetId: TargetId
  ): PersistencePromise<void>;
  /**
   * Removes all the keys in the query results of the given target ID.
   *
   * Multi-Tab Note: This operation should only be called by the primary client.
   */
  removeMatchingKeysForTargetId(
    transaction: PersistenceTransaction,
    targetId: TargetId
  ): PersistencePromise<void>;
  /**
   * Returns the document keys that match the provided target ID.
   */
  getMatchingKeysForTargetId(
    transaction: PersistenceTransaction,
    targetId: TargetId
  ): PersistencePromise<DocumentKeySet>;
  /**
   * Returns a new target ID that is higher than any query in the cache. If
   * there are no queries in the cache, returns the first valid target ID.
   * Allocated target IDs are persisted and `allocateTargetId()` will never
   * return the same ID twice.
   */
  allocateTargetId(
    transaction: PersistenceTransaction
  ): PersistencePromise<TargetId>;
  containsKey(
    transaction: PersistenceTransaction,
    key: DocumentKey
  ): PersistencePromise<boolean>;
}

/**
 * A TargetChange specifies the set of changes for a specific target as part of
 * a RemoteEvent. These changes track which documents are added, modified or
 * removed, as well as the target's resume token and whether the target is
 * marked CURRENT.
 * The actual changes *to* documents are not part of the TargetChange since
 * documents may be part of multiple targets.
 */
declare class TargetChange {
  /**
   * An opaque, server-assigned token that allows watching a query to be resumed
   * after disconnecting without retransmitting all the data that matches the
   * query. The resume token essentially identifies a point in time from which
   * the server should resume sending results.
   */
  readonly resumeToken: ByteString;
  /**
   * The "current" (synced) status of this target. Note that "current"
   * has special meaning in the RPC protocol that implies that a target is
   * both up-to-date and consistent with the rest of the watch stream.
   */
  readonly current: boolean;
  /**
   * The set of documents that were newly assigned to this target as part of
   * this remote event.
   */
  readonly addedDocuments: DocumentKeySet;
  /**
   * The set of documents that were already assigned to this target but received
   * an update during this remote event.
   */
  readonly modifiedDocuments: DocumentKeySet;
  /**
   * The set of documents that were removed from this target as part of this
   * remote event.
   */
  readonly removedDocuments: DocumentKeySet;
  constructor(
    /**
     * An opaque, server-assigned token that allows watching a query to be resumed
     * after disconnecting without retransmitting all the data that matches the
     * query. The resume token essentially identifies a point in time from which
     * the server should resume sending results.
     */
    resumeToken: ByteString,
    /**
     * The "current" (synced) status of this target. Note that "current"
     * has special meaning in the RPC protocol that implies that a target is
     * both up-to-date and consistent with the rest of the watch stream.
     */
    current: boolean,
    /**
     * The set of documents that were newly assigned to this target as part of
     * this remote event.
     */
    addedDocuments: DocumentKeySet,
    /**
     * The set of documents that were already assigned to this target but received
     * an update during this remote event.
     */
    modifiedDocuments: DocumentKeySet,
    /**
     * The set of documents that were removed from this target as part of this
     * remote event.
     */
    removedDocuments: DocumentKeySet
  );
  /**
   * This method is used to create a synthesized TargetChanges that can be used to
   * apply a CURRENT status change to a View (for queries executed in a different
   * tab) or for new queries (to raise snapshots with correct CURRENT status).
   */
  static createSynthesizedTargetChangeForCurrentChange(
    targetId: TargetId,
    current: boolean
  ): TargetChange;
}

declare type TargetChangeTargetChangeType =
  | 'NO_CHANGE'
  | 'ADD'
  | 'REMOVE'
  | 'CURRENT'
  | 'RESET';

/**
 * An immutable set of metadata that the local store tracks for each target.
 */
declare class TargetData {
  /** The target being listened to. */
  readonly target: Target;
  /**
   * The target ID to which the target corresponds; Assigned by the
   * LocalStore for user listens and by the SyncEngine for limbo watches.
   */
  readonly targetId: TargetId;
  /** The purpose of the target. */
  readonly purpose: TargetPurpose;
  /**
   * The sequence number of the last transaction during which this target data
   * was modified.
   */
  readonly sequenceNumber: ListenSequenceNumber;
  /** The latest snapshot version seen for this target. */
  readonly snapshotVersion: SnapshotVersion;
  /**
   * The maximum snapshot version at which the associated view
   * contained no limbo documents.
   */
  readonly lastLimboFreeSnapshotVersion: SnapshotVersion;
  /**
   * An opaque, server-assigned token that allows watching a target to be
   * resumed after disconnecting without retransmitting all the data that
   * matches the target. The resume token essentially identifies a point in
   * time from which the server should resume sending results.
   */
  readonly resumeToken: ByteString;
  constructor(
    /** The target being listened to. */
    target: Target,
    /**
     * The target ID to which the target corresponds; Assigned by the
     * LocalStore for user listens and by the SyncEngine for limbo watches.
     */
    targetId: TargetId,
    /** The purpose of the target. */
    purpose: TargetPurpose,
    /**
     * The sequence number of the last transaction during which this target data
     * was modified.
     */
    sequenceNumber: ListenSequenceNumber,
    /** The latest snapshot version seen for this target. */
    snapshotVersion?: SnapshotVersion,
    /**
     * The maximum snapshot version at which the associated view
     * contained no limbo documents.
     */
    lastLimboFreeSnapshotVersion?: SnapshotVersion,
    /**
     * An opaque, server-assigned token that allows watching a target to be
     * resumed after disconnecting without retransmitting all the data that
     * matches the target. The resume token essentially identifies a point in
     * time from which the server should resume sending results.
     */
    resumeToken?: ByteString
  );
  /** Creates a new target data instance with an updated sequence number. */
  withSequenceNumber(sequenceNumber: number): TargetData;
  /**
   * Creates a new target data instance with an updated resume token and
   * snapshot version.
   */
  withResumeToken(
    resumeToken: ByteString,
    snapshotVersion: SnapshotVersion
  ): TargetData;
  /**
   * Creates a new target data instance with an updated last limbo free
   * snapshot version number.
   */
  withLastLimboFreeSnapshotVersion(
    lastLimboFreeSnapshotVersion: SnapshotVersion
  ): TargetData;
}

/**
 * A locally-assigned ID used to refer to a target being watched via the
 * Watch service.
 */
declare type TargetId = number;

/** An enumeration of the different purposes we have for targets. */
declare const enum TargetPurpose {
  /** A regular, normal query target. */
  Listen = 0,
  /**
   * The query target was used to refill a query after an existence filter mismatch.
   */
  ExistenceFilterMismatch = 1,
  /** The query target was used to resolve a limbo document. */
  LimboResolution = 2
}

/**
 * Represents the state of bundle loading tasks.
 *
 * Both 'Error' and 'Success' are sinking state: task will abort or complete and there will
 * be no more updates after they are reported.
 */
export declare type TaskState = 'Error' | 'Running' | 'Success';

/**
 * Terminates the provided Firestore instance.
 *
 * After calling `terminate()` only the `clearIndexedDbPersistence()` function
 * may be used. Any other function will throw a `FirestoreError`.
 *
 * To restart after termination, create a new instance of FirebaseFirestore with
 * {@link getFirestore}.
 *
 * Termination does not cancel any pending writes, and any promises that are
 * awaiting a response from the server will not be resolved. If you have
 * persistence enabled, the next time you start this instance, it will resume
 * sending these writes to the server.
 *
 * Note: Under normal circumstances, calling `terminate()` is not required. This
 * function is useful only when you want to force this instance to release all
 * of its resources or in combination with `clearIndexedDbPersistence()` to
 * ensure that all local state is destroyed between test runs.
 *
 * @returns A promise that is resolved when the instance has been successfully
 * terminated.
 */
export declare function terminate(firestore: FirebaseFirestore): Promise<void>;

/**
 * Wellknown "timer" IDs used when scheduling delayed operations on the
 * AsyncQueue. These IDs can then be used from tests to check for the presence
 * of operations or to run them early.
 *
 * The string values are used when encoding these timer IDs in JSON spec tests.
 */
declare const enum TimerId {
  /** All can be used with runDelayedOperationsEarly() to run all timers. */
  All = 'all',
  /**
   * The following 4 timers are used in persistent_stream.ts for the listen and
   * write streams. The "Idle" timer is used to close the stream due to
   * inactivity. The "ConnectionBackoff" timer is used to restart a stream once
   * the appropriate backoff delay has elapsed.
   */
  ListenStreamIdle = 'listen_stream_idle',
  ListenStreamConnectionBackoff = 'listen_stream_connection_backoff',
  WriteStreamIdle = 'write_stream_idle',
  WriteStreamConnectionBackoff = 'write_stream_connection_backoff',
  /**
   * A timer used in online_state_tracker.ts to transition from
   * OnlineState.Unknown to Offline after a set timeout, rather than waiting
   * indefinitely for success or failure.
   */
  OnlineStateTimeout = 'online_state_timeout',
  /**
   * A timer used to update the client metadata in IndexedDb, which is used
   * to determine the primary leaseholder.
   */
  ClientMetadataRefresh = 'client_metadata_refresh',
  /** A timer used to periodically attempt LRU Garbage collection */
  LruGarbageCollection = 'lru_garbage_collection',
  /**
   * A timer used to retry transactions. Since there can be multiple concurrent
   * transactions, multiple of these may be in the queue at a given time.
   */
  TransactionRetry = 'transaction_retry',
  /**
   * A timer used to retry operations scheduled via retryable AsyncQueue
   * operations.
   */
  AsyncQueueRetry = 'async_queue_retry'
}

/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
/**
 * A `Timestamp` represents a point in time independent of any time zone or
 * calendar, represented as seconds and fractions of seconds at nanosecond
 * resolution in UTC Epoch time.
 *
 * It is encoded using the Proleptic Gregorian Calendar which extends the
 * Gregorian calendar backwards to year one. It is encoded assuming all minutes
 * are 60 seconds long, i.e. leap seconds are "smeared" so that no leap second
 * table is needed for interpretation. Range is from 0001-01-01T00:00:00Z to
 * 9999-12-31T23:59:59.999999999Z.
 *
 * For examples and further specifications, refer to the
 * {@link https://github.com/google/protobuf/blob/master/src/google/protobuf/timestamp.proto | Timestamp definition}.
 */
export declare class Timestamp {
  readonly seconds: number;
  readonly nanoseconds: number;
  /**
   * Creates a new timestamp with the current date, with millisecond precision.
   *
   * @returns a new timestamp representing the current date.
   */
  static now(): Timestamp;
  /**
   * Creates a new timestamp from the given date.
   *
   * @param date - The date to initialize the `Timestamp` from.
   * @returns A new `Timestamp` representing the same point in time as the given
   *     date.
   */
  static fromDate(date: Date): Timestamp;
  /**
   * Creates a new timestamp from the given number of milliseconds.
   *
   * @param milliseconds - Number of milliseconds since Unix epoch
   *     1970-01-01T00:00:00Z.
   * @returns A new `Timestamp` representing the same point in time as the given
   *     number of milliseconds.
   */
  static fromMillis(milliseconds: number): Timestamp;
  /**
   * Creates a new timestamp.
   *
   * @param seconds - The number of seconds of UTC time since Unix epoch
   *     1970-01-01T00:00:00Z. Must be from 0001-01-01T00:00:00Z to
   *     9999-12-31T23:59:59Z inclusive.
   * @param nanoseconds - The non-negative fractions of a second at nanosecond
   *     resolution. Negative second values with fractions must still have
   *     non-negative nanoseconds values that count forward in time. Must be
   *     from 0 to 999,999,999 inclusive.
   */
  constructor(seconds: number, nanoseconds: number);
  /**
   * Converts a `Timestamp` to a JavaScript `Date` object. This conversion causes
   * a loss of precision since `Date` objects only support millisecond precision.
   *
   * @returns JavaScript `Date` object representing the same point in time as
   *     this `Timestamp`, with millisecond precision.
   */
  toDate(): Date;
  /**
   * Converts a `Timestamp` to a numeric timestamp (in milliseconds since
   * epoch). This operation causes a loss of precision.
   *
   * @returns The point in time corresponding to this timestamp, represented as
   *     the number of milliseconds since Unix epoch 1970-01-01T00:00:00Z.
   */
  toMillis(): number;
  _compareTo(other: Timestamp): number;
  /**
   * Returns true if this `Timestamp` is equal to the provided one.
   *
   * @param other - The `Timestamp` to compare against.
   * @returns true if this `Timestamp` is equal to the provided one.
   */
  isEqual(other: Timestamp): boolean;
  toString(): string;
  toJSON(): {
    seconds: number;
    nanoseconds: number;
  };
  /**
   * Converts this object to a primitive string, which allows Timestamp objects to be compared
   * using the `>`, `<=`, `>=` and `>` operators.
   */
  valueOf(): string;
}

declare type Timestamp_2 =
  | string
  | {
      seconds?: string | number;
      nanos?: number;
    };

declare interface Token {
  /** Type of token. */
  type: TokenType;
  /**
   * The user with which the token is associated (used for persisting user
   * state on disk, etc.).
   */
  user: User;
  /** Extra header values to be passed along with a request */
  authHeaders: {
    [header: string]: string;
  };
}

declare type TokenType = 'OAuth' | 'FirstParty';

/**
 * A reference to a transaction.
 *
 * The `Transaction` object passed to a transaction's `updateFunction` provides
 * the methods to read and write data within the transaction context. See
 * {@link runTransaction}.
 */
export declare class Transaction extends Transaction_2 {
  protected readonly _firestore: FirebaseFirestore;
  /** @hideconstructor */
  constructor(_firestore: FirebaseFirestore, _transaction: Transaction_3);
  /**
   * Reads the document referenced by the provided {@link DocumentReference}.
   *
   * @param documentRef - A reference to the document to be read.
   * @returns A `DocumentSnapshot` with the read data.
   */
  get<T>(documentRef: DocumentReference<T>): Promise<DocumentSnapshot<T>>;
}

/**
 * A reference to a transaction.
 *
 * The `Transaction` object passed to a transaction's `updateFunction` provides
 * the methods to read and write data within the transaction context. See
 * {@link runTransaction}.
 */
declare class Transaction_2 {
  protected readonly _firestore: FirebaseFirestore_2;
  private readonly _transaction;
  private readonly _dataReader;
  /** @hideconstructor */
  constructor(_firestore: FirebaseFirestore_2, _transaction: Transaction_3);
  /**
   * Reads the document referenced by the provided {@link DocumentReference}.
   *
   * @param documentRef - A reference to the document to be read.
   * @returns A `DocumentSnapshot` with the read data.
   */
  get<T>(documentRef: DocumentReference<T>): Promise<DocumentSnapshot_2<T>>;
  /**
   * Writes to the document referred to by the provided {@link
   * DocumentReference}. If the document does not exist yet, it will be created.
   *
   * @param documentRef - A reference to the document to be set.
   * @param data - An object of the fields and values for the document.
   * @returns This `Transaction` instance. Used for chaining method calls.
   */
  set<T>(documentRef: DocumentReference<T>, data: T): this;
  /**
   * Writes to the document referred to by the provided {@link
   * DocumentReference}. If the document does not exist yet, it will be created.
   * If you provide `merge` or `mergeFields`, the provided data can be merged
   * into an existing document.
   *
   * @param documentRef - A reference to the document to be set.
   * @param data - An object of the fields and values for the document.
   * @param options - An object to configure the set behavior.
   * @returns This `Transaction` instance. Used for chaining method calls.
   */
  set<T>(
    documentRef: DocumentReference<T>,
    data: Partial<T>,
    options: SetOptions
  ): this;
  /**
   * Updates fields in the document referred to by the provided {@link
   * DocumentReference}. The update will fail if applied to a document that does
   * not exist.
   *
   * @param documentRef - A reference to the document to be updated.
   * @param data - An object containing the fields and values with which to
   * update the document. Fields can contain dots to reference nested fields
   * within the document.
   * @returns This `Transaction` instance. Used for chaining method calls.
   */
  update(documentRef: DocumentReference<unknown>, data: UpdateData): this;
  /**
   * Updates fields in the document referred to by the provided {@link
   * DocumentReference}. The update will fail if applied to a document that does
   * not exist.
   *
   * Nested fields can be updated by providing dot-separated field path
   * strings or by providing `FieldPath` objects.
   *
   * @param documentRef - A reference to the document to be updated.
   * @param field - The first field to update.
   * @param value - The first value.
   * @param moreFieldsAndValues - Additional key/value pairs.
   * @returns This `Transaction` instance. Used for chaining method calls.
   */
  update(
    documentRef: DocumentReference<unknown>,
    field: string | FieldPath,
    value: unknown,
    ...moreFieldsAndValues: unknown[]
  ): this;
  /**
   * Deletes the document referred to by the provided {@link DocumentReference}.
   *
   * @param documentRef - A reference to the document to be deleted.
   * @returns This `Transaction` instance. Used for chaining method calls.
   */
  delete(documentRef: DocumentReference<unknown>): this;
}

/**
 * Internal transaction object responsible for accumulating the mutations to
 * perform and the base versions for any documents read.
 */
declare class Transaction_3 {
  private datastore;
  private readVersions;
  private mutations;
  private committed;
  /**
   * A deferred usage error that occurred previously in this transaction that
   * will cause the transaction to fail once it actually commits.
   */
  private lastWriteError;
  /**
   * Set of documents that have been written in the transaction.
   *
   * When there's more than one write to the same key in a transaction, any
   * writes after the first are handled differently.
   */
  private writtenDocs;
  constructor(datastore: Datastore);
  lookup(keys: DocumentKey[]): Promise<MaybeDocument[]>;
  set(key: DocumentKey, data: ParsedSetData): void;
  update(key: DocumentKey, data: ParsedUpdateData): void;
  delete(key: DocumentKey): void;
  commit(): Promise<void>;
  private recordVersion;
  /**
   * Returns the version of this document when it was read in this transaction,
   * as a precondition, or no precondition if it was not read.
   */
  private precondition;
  /**
   * Returns the precondition for a document if the operation is an update.
   */
  private preconditionForUpdate;
  private write;
  private ensureCommitNotCalled;
}

/** Used to represent a field transform on a mutation. */
declare class TransformOperation {
  private _;
}

declare type UnaryFilterOp =
  | 'OPERATOR_UNSPECIFIED'
  | 'IS_NAN'
  | 'IS_NULL'
  | 'IS_NOT_NAN'
  | 'IS_NOT_NULL';

export declare interface Unsubscribe {
  (): void;
}

/**
 * An untyped Firestore Data Converter interface that is shared between the
 * lite, firestore-exp and classic SDK.
 */
declare interface UntypedFirestoreDataConverter<T> {
  toFirestore(modelObject: T): DocumentData_2;
  toFirestore(modelObject: Partial<T>, options: SetOptions_2): DocumentData_2;
  fromFirestore(snapshot: unknown, options?: unknown): T;
}

/**
 * Update data (for use with {@link updateDoc}) consists of field paths (e.g.
 * 'foo' or 'foo.baz') mapped to values. Fields that contain dots reference
 * nested fields within the document.
 */
export declare interface UpdateData {
  [fieldPath: string]: any;
}

/**
 * Updates fields in the document referred to by the specified
 * `DocumentReference`. The update will fail if applied to a document that does
 * not exist.
 *
 * @param reference - A reference to the document to update.
 * @param data - An object containing the fields and values with which to
 * update the document. Fields can contain dots to reference nested fields
 * within the document.
 * @returns A Promise resolved once the data has been successfully written
 * to the backend (note that it won't resolve while you're offline).
 */
export declare function updateDoc(
  reference: DocumentReference<unknown>,
  data: UpdateData
): Promise<void>;

/**
 * Updates fields in the document referred to by the specified
 * `DocumentReference` The update will fail if applied to a document that does
 * not exist.
 *
 * Nested fields can be updated by providing dot-separated field path
 * strings or by providing `FieldPath` objects.
 *
 * @param reference - A reference to the document to update.
 * @param field - The first field to update.
 * @param value - The first value.
 * @param moreFieldsAndValues - Additional key value pairs.
 * @returns A Promise resolved once the data has been successfully written
 * to the backend (note that it won't resolve while you're offline).
 */
export declare function updateDoc(
  reference: DocumentReference<unknown>,
  field: string | FieldPath,
  value: unknown,
  ...moreFieldsAndValues: unknown[]
): Promise<void>;

/**
 * Modify this instance to communicate with the Cloud Firestore emulator.
 *
 * Note: This must be called before this instance has been used to do any
 * operations.
 *
 * @param firestore - The Firestore instance to configure to connect to the
 * emulator.
 * @param host - the emulator host (ex: localhost).
 * @param port - the emulator port (ex: 9000).
 */
export declare function useFirestoreEmulator(
  firestore: FirebaseFirestore_2,
  host: string,
  port: number
): void;

/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
/**
 * Simple wrapper around a nullable UID. Mostly exists to make code more
 * readable.
 */
declare class User {
  readonly uid: string | null;
  /** A user with a null UID. */
  static readonly UNAUTHENTICATED: User;
  static readonly GOOGLE_CREDENTIALS: User;
  static readonly FIRST_PARTY: User;
  constructor(uid: string | null);
  isAuthenticated(): boolean;
  /**
   * Returns a key representing this user, suitable for inclusion in a
   * dictionary.
   */
  toKey(): string;
  isEqual(otherUser: User): boolean;
}

declare type Value = firestoreV1ApiClientInterfaces.Value;

declare type ValueNullValue = 'NULL_VALUE';

declare class ViewSnapshot {
  readonly query: Query_2;
  readonly docs: DocumentSet;
  readonly oldDocs: DocumentSet;
  readonly docChanges: DocumentViewChange[];
  readonly mutatedKeys: DocumentKeySet;
  readonly fromCache: boolean;
  readonly syncStateChanged: boolean;
  readonly excludesMetadataChanges: boolean;
  constructor(
    query: Query_2,
    docs: DocumentSet,
    oldDocs: DocumentSet,
    docChanges: DocumentViewChange[],
    mutatedKeys: DocumentKeySet,
    fromCache: boolean,
    syncStateChanged: boolean,
    excludesMetadataChanges: boolean
  );
  /** Returns a view snapshot as if all documents in the snapshot were added. */
  static fromInitialDocuments(
    query: Query_2,
    documents: DocumentSet,
    mutatedKeys: DocumentKeySet,
    fromCache: boolean
  ): ViewSnapshot;
  get hasPendingWrites(): boolean;
  isEqual(other: ViewSnapshot): boolean;
}

/**
 * Waits until all currently pending writes for the active user have been
 * acknowledged by the backend.
 *
 * The returned Promise resolves immediately if there are no outstanding writes.
 * Otherwise, the Promise waits for all previously issued writes (including
 * those written in a previous app session), but it does not wait for writes
 * that were added after the function is called. If you want to wait for
 * additional writes, call `waitForPendingWrites()` again.
 *
 * Any outstanding `waitForPendingWrites()` Promises are rejected during user
 * changes.
 *
 * @returns A Promise which resolves when all currently pending writes have been
 * acknowledged by the backend.
 */
export declare function waitForPendingWrites(
  firestore: FirebaseFirestore
): Promise<void>;

/**
 * Creates a `QueryConstraint` that enforces that documents must contain the
 * specified field and that the value should satisfy the relation constraint
 * provided.
 *
 * @param fieldPath - The path to compare
 * @param opStr - The operation string (e.g "&lt;", "&lt;=", "==", "&lt;",
 *   "&lt;=", "!=").
 * @param value - The value for comparison
 * @returns The created `Query`.
 */
export declare function where(
  fieldPath: string | FieldPath,
  opStr: WhereFilterOp,
  value: unknown
): QueryConstraint;

/**
 * Filter conditions in a {@link where} clause are specified using the
 * strings '&lt;', '&lt;=', '==', '!=', '&gt;=', '&gt;', 'array-contains', 'in',
 * 'array-contains-any', and 'not-in'.
 */
export declare type WhereFilterOp =
  | '<'
  | '<='
  | '=='
  | '!='
  | '>='
  | '>'
  | 'array-contains'
  | 'in'
  | 'array-contains-any'
  | 'not-in';

/**
 * A write batch, used to perform multiple writes as a single atomic unit.
 *
 * A `WriteBatch` object can be acquired by calling {@link writeBatch}. It
 * provides methods for adding writes to the write batch. None of the writes
 * will be committed (or visible locally) until {@link WriteBatch#commit} is
 * called.
 */
export declare class WriteBatch {
  private readonly _firestore;
  private readonly _commitHandler;
  private readonly _dataReader;
  private _mutations;
  private _committed;
  /** @hideconstructor */
  constructor(
    _firestore: FirebaseFirestore_2,
    _commitHandler: (m: Mutation[]) => Promise<void>
  );
  /**
   * Writes to the document referred to by the provided {@link
   * DocumentReference}. If the document does not exist yet, it will be created.
   *
   * @param documentRef - A reference to the document to be set.
   * @param data - An object of the fields and values for the document.
   * @returns This `WriteBatch` instance. Used for chaining method calls.
   */
  set<T>(documentRef: DocumentReference<T>, data: T): WriteBatch;
  /**
   * Writes to the document referred to by the provided {@link
   * DocumentReference}. If the document does not exist yet, it will be created.
   * If you provide `merge` or `mergeFields`, the provided data can be merged
   * into an existing document.
   *
   * @param documentRef - A reference to the document to be set.
   * @param data - An object of the fields and values for the document.
   * @param options - An object to configure the set behavior.
   * @returns This `WriteBatch` instance. Used for chaining method calls.
   */
  set<T>(
    documentRef: DocumentReference<T>,
    data: Partial<T>,
    options: SetOptions
  ): WriteBatch;
  /**
   * Updates fields in the document referred to by the provided {@link
   * DocumentReference}. The update will fail if applied to a document that does
   * not exist.
   *
   * @param documentRef - A reference to the document to be updated.
   * @param data - An object containing the fields and values with which to
   * update the document. Fields can contain dots to reference nested fields
   * within the document.
   * @returns This `WriteBatch` instance. Used for chaining method calls.
   */
  update(documentRef: DocumentReference<unknown>, data: UpdateData): WriteBatch;
  /**
   * Updates fields in the document referred to by this {@link
   * DocumentReference}. The update will fail if applied to a document that does
   * not exist.
   *
   * Nested fields can be update by providing dot-separated field path strings
   * or by providing `FieldPath` objects.
   *
   * @param documentRef - A reference to the document to be updated.
   * @param field - The first field to update.
   * @param value - The first value.
   * @param moreFieldsAndValues - Additional key value pairs.
   * @returns This `WriteBatch` instance. Used for chaining method calls.
   */
  update(
    documentRef: DocumentReference<unknown>,
    field: string | FieldPath,
    value: unknown,
    ...moreFieldsAndValues: unknown[]
  ): WriteBatch;
  /**
   * Deletes the document referred to by the provided {@link DocumentReference}.
   *
   * @param documentRef - A reference to the document to be deleted.
   * @returns This `WriteBatch` instance. Used for chaining method calls.
   */
  delete(documentRef: DocumentReference<unknown>): WriteBatch;
  /**
   * Commits all of the writes in this write batch as a single atomic unit.
   *
   * The result of these writes will only be reflected in document reads that
   * occur after the returned Promise resolves. If the client is offline, the
   * write fails. If you would like to see local modifications or buffer writes
   * until the client is online, use the full Firestore SDK.
   *
   * @returns A Promise resolved once all of the writes in the batch have been
   * successfully written to the backend as an atomic unit (note that it won't
   * resolve while you're offline).
   */
  commit(): Promise<void>;
  private _verifyNotCommitted;
}

/**
 * Creates a write batch, used for performing multiple writes as a single
 * atomic operation. The maximum number of writes allowed in a single WriteBatch
 * is 500.
 *
 * Unlike transactions, write batches are persisted offline and therefore are
 * preferable when you don't need to condition your writes on read data.
 *
 * @returns A `WriteBatch` that can be used to atomically execute multiple
 * writes.
 */
export declare function writeBatch(firestore: FirebaseFirestore): WriteBatch;

export {};
